{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DIFFUSERS_SLOW_IMPORT' from 'diffusers.utils' (/home/cam/anaconda3/envs/test_mujoco/lib/python3.9/site-packages/diffusers/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschedulers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscheduling_ddpm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DDPMScheduler\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EMAModel\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_scheduler\n",
      "File \u001b[0;32m~/anaconda3/envs/test_mujoco/lib/python3.9/site-packages/diffusers/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.29.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     DIFFUSERS_SLOW_IMPORT,\n\u001b[1;32m      7\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m      8\u001b[0m     _LazyModule,\n\u001b[1;32m      9\u001b[0m     is_flax_available,\n\u001b[1;32m     10\u001b[0m     is_k_diffusion_available,\n\u001b[1;32m     11\u001b[0m     is_librosa_available,\n\u001b[1;32m     12\u001b[0m     is_note_seq_available,\n\u001b[1;32m     13\u001b[0m     is_onnx_available,\n\u001b[1;32m     14\u001b[0m     is_scipy_available,\n\u001b[1;32m     15\u001b[0m     is_torch_available,\n\u001b[1;32m     16\u001b[0m     is_torchsde_available,\n\u001b[1;32m     17\u001b[0m     is_transformers_available,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Lazy Import based on\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# https://github.com/huggingface/transformers/blob/main/src/transformers/__init__.py\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# When adding a new object to this init, please add it to `_import_structure`. The `_import_structure` is a dictionary submodule to list of object names,\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# and is used to defer the actual importing for when the objects are requested.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# This way `import diffusers` provides the names in the namespace without actually importing anything (and especially none of the backends).\u001b[39;00m\n\u001b[1;32m     28\u001b[0m _import_structure \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfiguration_utils\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfigMixin\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFromOriginalModelMixin\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     ],\n\u001b[1;32m     52\u001b[0m }\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DIFFUSERS_SLOW_IMPORT' from 'diffusers.utils' (/home/cam/anaconda3/envs/test_mujoco/lib/python3.9/site-packages/diffusers/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
    "from diffusers.training_utils import EMAModel\n",
    "from diffusers.optimization import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "import submodules.data_filter as _df\n",
    "import diffusion_pipline.data_processing as dproc\n",
    "import diffusion_pipline.model as md\n",
    "import submodules.cleaned_file_parser as cfp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/home/cam/Documents/raj/diffusion_policy_cam/no-sync/checkpoints/checkpoint_3Body_SSSS_epoch_399.pth'\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation and action dimensions corrsponding to\n",
    "\n",
    "num_epochs =200\n",
    "obs_dim = 93\n",
    "action_dim = 18\n",
    "# parameters\n",
    "pred_horizon = 16\n",
    "obs_horizon = 2\n",
    "action_horizon = 8\n",
    "target_fps = 120.0\n",
    "\n",
    "action_item = ['chisel', 'gripper', 'battery']\n",
    "obs_item = None\n",
    "\n",
    "\n",
    "# create network object\n",
    "noise_pred_net = md.ConditionalUnet1D(\n",
    "    input_dim=action_dim,\n",
    "    global_cond_dim=obs_dim*obs_horizon\n",
    ")\n",
    "\n",
    "# example inputs\n",
    "noised_action = torch.randn((1, pred_horizon, action_dim))\n",
    "obs = torch.zeros((1, obs_horizon, obs_dim))\n",
    "diffusion_iter = torch.zeros((1,))\n",
    "\n",
    "# the noise prediction network\n",
    "# takes noisy action, diffusion iteration and observation as input\n",
    "# predicts the noise added to action\n",
    "noise = noise_pred_net(\n",
    "    sample=noised_action,\n",
    "    timestep=diffusion_iter,\n",
    "    global_cond=obs.flatten(start_dim=1))\n",
    "\n",
    "# illustration of removing noise\n",
    "# the actual noise removal is performed by NoiseScheduler\n",
    "# and is dependent on the diffusion noise schedule\n",
    "denoised_action = noised_action - noise\n",
    "\n",
    "# for this demo, we use DDPMScheduler with 100 diffusion iterations\n",
    "num_diffusion_iters = 100\n",
    "noise_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=num_diffusion_iters,\n",
    "    # the choise of beta schedule has big impact on performance\n",
    "    # we found squared cosine works the best\n",
    "    beta_schedule='squaredcos_cap_v2',\n",
    "    # clip output to [-1,1] to improve stability\n",
    "    clip_sample=True,\n",
    "    # our network predicts noise (instead of denoised action)\n",
    "    prediction_type='epsilon'\n",
    ")\n",
    "\n",
    "# device transfer\n",
    "device = torch.device('cuda')\n",
    "_ = noise_pred_net.to(device)\n",
    "\n",
    "# Exponential Moving Average\n",
    "# accelerates training and improves stability\n",
    "# holds a copy of the model weights\n",
    "ema = EMAModel(\n",
    "    parameters=noise_pred_net.parameters(),\n",
    "    power=0.75)\n",
    "\n",
    "# Standard ADAM optimizer\n",
    "# Note that EMA parametesr are not optimized\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=noise_pred_net.parameters(),\n",
    "    lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "# Cosine LR schedule with linear warmup\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='cosine',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=200,\n",
    "    num_training_steps=checkpoint['len_dataloader'] * num_epochs\n",
    ")\n",
    "\n",
    "ema_noise_pred_net = noise_pred_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_pred_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "ema.load_state_dict(checkpoint['ema_state_dict'])\n",
    "start_epoch = checkpoint['epoch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset from file\n",
    "# path_name = \"/home/cam/Downloads/Supporting Data - Sheet1.csv\"\n",
    "base_path = \"no_sync/data_chisel_task/2-cleaned_interpolation_with_offset/offset_interpolated_test_traj/\"\n",
    "\n",
    "# Load data\n",
    "dict_of_df_rigid_test = {}\n",
    "dict_of_df_rigid_velocity_test = {}\n",
    "dict_of_df_marker_test = {}\n",
    "name = []\n",
    "\n",
    "for file in os.listdir(base_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        name.append(file)\n",
    "        path_name = base_path + file\n",
    "        data_test = cfp.DataParser.from_euler_file(file_path = path_name, target_fps=target_fps, filter=True, window_size=15, polyorder=3)\n",
    "\n",
    "        marker_data = data_test.get_marker_Txyz()\n",
    "        data_time = data_test.get_time().astype(float)\n",
    "        data_state_dict = data_test.get_rigid_TxyzRxyz()\n",
    "\n",
    "        # use the time and state data to get the velocity data\n",
    "        data_velocity_state_dict = {}\n",
    "        data_velocity_dict = {}\n",
    "        for key in data_state_dict.keys():\n",
    "            if key != 'battery':\n",
    "                data_velocity = []\n",
    "                data_velocity_state = []\n",
    "                for i in range(0, len(data_time) -1):\n",
    "                    veloctiy_val = (data_state_dict[key][i + 1] - data_state_dict[key][i]) / (data_time[i + 1] - data_time[i])\n",
    "                    data_velocity.append(veloctiy_val)\n",
    "                    data_velocity_state.append(np.concatenate((data_state_dict[key][i], veloctiy_val), axis=0).tolist())\n",
    "                velocity_state_data = pd.DataFrame(data_velocity_state, columns= [f'{key}_X', f'{key}_Y', f'{key}_Z', f'{key}_x', f'{key}_y', f'{key}_z', f'{key}_Xv', f'{key}_Yv', f'{key}_Zv', f'{key}_xv', f'{key}_yv', f'{key}_zv'])\n",
    "                filtered_velocity_state = _df.apply_savgol_filter(velocity_state_data, window_size = 15, polyorder = 3, time_frame= False)\n",
    "                data_velocity_state_dict[key] = filtered_velocity_state.values\n",
    "                velocity_data = pd.DataFrame(data_velocity, columns= [f'{key}_Xv', f'{key}_Yv', f'{key}_Zv', f'{key}_xv', f'{key}_yv', f'{key}_zv'])\n",
    "                filtered_velocity = _df.apply_savgol_filter(velocity_data, window_size = 15, polyorder = 3, time_frame= False)\n",
    "                data_velocity_dict[key] = filtered_velocity.values\n",
    "            else:\n",
    "                data_velocity_state_dict[key] = data_state_dict[key]\n",
    "\n",
    "\n",
    "        dicts = [data_velocity_state_dict, data_velocity_dict, marker_data]\n",
    "        trimmed_dicts = _df.trim_lists_in_dicts(dicts)\n",
    "\n",
    "        \n",
    "        dict_of_df_rigid_test[file] = trimmed_dicts[0]\n",
    "        dict_of_df_rigid_velocity_test[file] = trimmed_dicts[1]\n",
    "        dict_of_df_marker_test[file] = trimmed_dicts[2]\n",
    "\n",
    "\n",
    "item_name_test = data_test.rigid_bodies\n",
    "marker_name_test = data_test.markers\n",
    "\n",
    "if len(dict_of_df_rigid_test) == len(dict_of_df_marker_test) == len(dict_of_df_rigid_velocity_test):\n",
    "\n",
    "    rigiddataset_test, index_test = _df.episode_combiner(dict_of_df_rigid_test, item_name_test)\n",
    "    velocitydataset_test, _ = _df.episode_combiner(dict_of_df_rigid_velocity_test, action_item)\n",
    "    markerdataset_test, _ = _df.episode_combiner(dict_of_df_marker_test, marker_name_test)\n",
    "    print(index_test[action_item[0]])\n",
    "\n",
    "\n",
    "indexes = index_test[action_item[0]]\n",
    "action = []\n",
    "obs = []\n",
    "for i in range(indexes[-1]):\n",
    "    a = np.concatenate([velocitydataset_test[item][i] for item in action_item])\n",
    "    b = np.concatenate([rigiddataset_test[item][i] for item in action_item] \n",
    "                       + [rigiddataset_test[item][i] for item in obs_item] \n",
    "                       + [markerdataset_test[item][i] for item in marker_name_test])\n",
    "\n",
    "    action.append(a)\n",
    "    obs.append(b)\n",
    "    \n",
    "# All demonstration episodes are concatinated in the first dimension N\n",
    "action = np.array(action, dtype=np.float64)\n",
    "obs = np.array(obs, dtype=np.float64)\n",
    "\n",
    "# Initialize lists to store segmented data\n",
    "splits_obs = []\n",
    "splits_action = []\n",
    "previous_index = 0\n",
    "\n",
    "# Iterate through episode_ends and slice action and obs accordingly\n",
    "for index in indexes:\n",
    "    splits_obs.append(obs[previous_index:index])  # Include index itself in the slice\n",
    "    splits_action.append(action[previous_index:index])\n",
    "    previous_index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "trajectories = {}\n",
    "losses_per_traj = {}\n",
    "for j in range(len(indexes)):\n",
    "    # get first observation\n",
    "    com_obs = splits_obs[j]\n",
    "    obs = splits_obs[j][0]\n",
    "    actions_test = splits_action[j]\n",
    "    # max_steps = len(test_data['action'])\n",
    "    max_steps = len(actions_test)\n",
    "    stats = checkpoint['dataset_stats']\n",
    "    # keep a queue of last 2 steps of observations\n",
    "    obs_deque = collections.deque(\n",
    "        [obs] * obs_horizon, maxlen=obs_horizon)\n",
    "\n",
    "    # save visualization and rewards\n",
    "    done = False\n",
    "    step_idx = 0\n",
    "    traj = []\n",
    "    loss_com = []\n",
    "    with tqdm(total=max_steps, desc=\"Eval\") as pbar:\n",
    "        while not done:\n",
    "            B = 1\n",
    "            # stack the last obs_horizon (2) number of observations\n",
    "            obs_seq = np.stack(obs_deque)\n",
    "            # normalize observation\n",
    "            nobs = dproc.normalize_data(obs_seq, stats=stats['obs'])\n",
    "            # device transfer\n",
    "            nobs = torch.from_numpy(nobs).to(device, dtype=torch.float32)\n",
    "            # infer action\n",
    "            with torch.no_grad():\n",
    "                # reshape observation to (B,obs_horizon*obs_dim)\n",
    "                obs_cond = nobs.unsqueeze(0).flatten(start_dim=1)\n",
    "                # print(obs_cond.shape)\n",
    "\n",
    "                # initialize action from Guassian noise\n",
    "                noisy_action = torch.randn(\n",
    "                    (B, pred_horizon, action_dim), device=device)\n",
    "                naction = noisy_action\n",
    "\n",
    "                # init scheduler\n",
    "                noise_scheduler.set_timesteps(num_diffusion_iters)\n",
    "\n",
    "                for k in noise_scheduler.timesteps:\n",
    "                    # predict noise\n",
    "                    noise_pred = ema_noise_pred_net(\n",
    "                        sample=naction,\n",
    "                        timestep=k,\n",
    "                        global_cond=obs_cond\n",
    "                    )\n",
    "\n",
    "                    # inverse diffusion step (remove noise)\n",
    "                    naction = noise_scheduler.step(\n",
    "                        model_output=noise_pred,\n",
    "                        timestep=k,\n",
    "                        sample=naction\n",
    "                    ).prev_sample\n",
    "\n",
    "            # unnormalize action\n",
    "            naction = naction.detach().to('cpu').numpy()\n",
    "            # (B, pred_horizon, action_dim)\n",
    "            naction = naction[0]\n",
    "            action_pred = dproc.unnormalize_data(naction, stats=stats['action'])\n",
    "\n",
    "            # only take action_horizon number of actions\n",
    "            start = obs_horizon - 1\n",
    "            end = start + action_horizon\n",
    "            action = action_pred[start:end,:]\n",
    "            traj.extend(action)\n",
    "            losses = []\n",
    "            pos_item1 = obs_deque[-1][:6]\n",
    "            pos_item2 = obs_deque[-1][12:18]\n",
    "            time_step = 1/120.0\n",
    "                \n",
    "            for i in range(len(action)):\n",
    "                if len(action) > len(actions_test):\n",
    "                    done = True\n",
    "                if done:\n",
    "                    break\n",
    "                loss_test = nn.functional.mse_loss(torch.tensor(action[i]), torch.tensor(actions_test[i]))\n",
    "                \n",
    "                action_vel_item1 = action[i][:6]\n",
    "                action_vel_item2 = action[i][6:12]\n",
    "                # print(\"Action_last ---\",action_last)\n",
    "                new_pos_item1 = pos_item1 + (action_vel_item1*time_step)\n",
    "                new_pos_item2 = pos_item2 + (action_vel_item2*time_step)\n",
    "                com_obs_part = com_obs[i][24:]\n",
    "                # Concatenating prediction to the obs lists\n",
    "                com_obs[i] = np.concatenate([new_pos_item1 , action_vel_item1 , new_pos_item2 , action_vel_item2 , com_obs_part]).tolist()\n",
    "                obs_deque.append(com_obs[i])\n",
    "                losses.append(loss_test.item())\n",
    "                # update progress bar\n",
    "                step_idx += 1\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(loss=np.mean(losses))\n",
    "                # print(i)\n",
    "                if step_idx > max_steps:\n",
    "                    done = True\n",
    "                if done:\n",
    "                    break\n",
    "            com_obs = com_obs[len(action):]\n",
    "            actions_test = actions_test[len(action):]\n",
    "            loss_com.append(np.mean(losses).tolist())\n",
    "    losses_per_traj[f\"{name[j]}\"] = np.nanmean(loss_com)\n",
    "    trajectories[f\"{name[j]}\"] = traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2nd_model_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
