{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusion policy import\n",
    "from typing import Tuple, Sequence, Dict, Union, Optional, List\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import collections\n",
    "import zarr\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
    "from diffusers.training_utils import EMAModel\n",
    "from diffusers.optimization import get_scheduler\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown ### **Network**\n",
    "#@markdown\n",
    "#@markdown Defines a 1D UNet architecture `ConditionalUnet1D`\n",
    "#@markdown as the noies prediction network\n",
    "#@markdown\n",
    "#@markdown Components\n",
    "#@markdown - `SinusoidalPosEmb` Positional encoding for the diffusion iteration k\n",
    "#@markdown - `Downsample1d` Strided convolution to reduce temporal resolution\n",
    "#@markdown - `Upsample1d` Transposed convolution to increase temporal resolution\n",
    "#@markdown - `Conv1dBlock` Conv1d --> GroupNorm --> Mish\n",
    "#@markdown - `ConditionalResidualBlock1D` Takes two inputs `x` and `cond`. \\\n",
    "#@markdown `x` is passed through 2 `Conv1dBlock` stacked together with residual connection.\n",
    "#@markdown `cond` is applied to `x` with [FiLM](https://arxiv.org/abs/1709.07871) conditioning.\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "\n",
    "class Downsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(dim, dim, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class Upsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose1d(dim, dim, 4, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Conv1dBlock(nn.Module):\n",
    "    '''\n",
    "        Conv1d --> GroupNorm --> Mish\n",
    "    '''\n",
    "\n",
    "    def __init__(self, inp_channels, out_channels, kernel_size, n_groups=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv1d(inp_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
    "            nn.GroupNorm(n_groups, out_channels),\n",
    "            nn.Mish(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class ConditionalResidualBlock1D(nn.Module):\n",
    "    def __init__(self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            cond_dim,\n",
    "            kernel_size=3,\n",
    "            n_groups=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Conv1dBlock(in_channels, out_channels, kernel_size, n_groups=n_groups),\n",
    "            Conv1dBlock(out_channels, out_channels, kernel_size, n_groups=n_groups),\n",
    "        ])\n",
    "\n",
    "        # FiLM modulation https://arxiv.org/abs/1709.07871\n",
    "        # predicts per-channel scale and bias\n",
    "        cond_channels = out_channels * 2\n",
    "        self.out_channels = out_channels\n",
    "        self.cond_encoder = nn.Sequential(\n",
    "            nn.Mish(),\n",
    "            nn.Linear(cond_dim, cond_channels),\n",
    "            nn.Unflatten(-1, (-1, 1))\n",
    "        )\n",
    "\n",
    "        # make sure dimensions compatible\n",
    "        self.residual_conv = nn.Conv1d(in_channels, out_channels, 1) \\\n",
    "            if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x, cond):\n",
    "        '''\n",
    "            x : [ batch_size x in_channels x horizon ]\n",
    "            cond : [ batch_size x cond_dim]\n",
    "\n",
    "            returns:\n",
    "            out : [ batch_size x out_channels x horizon ]\n",
    "        '''\n",
    "        out = self.blocks[0](x)\n",
    "        embed = self.cond_encoder(cond)\n",
    "\n",
    "        embed = embed.reshape(\n",
    "            embed.shape[0], 2, self.out_channels, 1)\n",
    "        scale = embed[:,0,...]\n",
    "        bias = embed[:,1,...]\n",
    "        out = scale * out + bias\n",
    "\n",
    "        out = self.blocks[1](out)\n",
    "        out = out + self.residual_conv(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConditionalUnet1D(nn.Module):\n",
    "    def __init__(self,\n",
    "        input_dim,\n",
    "        global_cond_dim,\n",
    "        diffusion_step_embed_dim=256,\n",
    "        down_dims=[256,512,1024],\n",
    "        kernel_size=5,\n",
    "        n_groups=8\n",
    "        ):\n",
    "        \"\"\"\n",
    "        input_dim: Dim of actions.\n",
    "        global_cond_dim: Dim of global conditioning applied with FiLM\n",
    "          in addition to diffusion step embedding. This is usually obs_horizon * obs_dim\n",
    "        diffusion_step_embed_dim: Size of positional encoding for diffusion iteration k\n",
    "        down_dims: Channel size for each UNet level.\n",
    "          The length of this array determines numebr of levels.\n",
    "        kernel_size: Conv kernel size\n",
    "        n_groups: Number of groups for GroupNorm\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        all_dims = [input_dim] + list(down_dims)\n",
    "        start_dim = down_dims[0]\n",
    "\n",
    "        dsed = diffusion_step_embed_dim\n",
    "        diffusion_step_encoder = nn.Sequential(\n",
    "            SinusoidalPosEmb(dsed),\n",
    "            nn.Linear(dsed, dsed * 4),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(dsed * 4, dsed),\n",
    "        )\n",
    "        cond_dim = dsed + global_cond_dim\n",
    "\n",
    "        in_out = list(zip(all_dims[:-1], all_dims[1:]))\n",
    "        mid_dim = all_dims[-1]\n",
    "        self.mid_modules = nn.ModuleList([\n",
    "            ConditionalResidualBlock1D(\n",
    "                mid_dim, mid_dim, cond_dim=cond_dim,\n",
    "                kernel_size=kernel_size, n_groups=n_groups\n",
    "            ),\n",
    "            ConditionalResidualBlock1D(\n",
    "                mid_dim, mid_dim, cond_dim=cond_dim,\n",
    "                kernel_size=kernel_size, n_groups=n_groups\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "        down_modules = nn.ModuleList([])\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (len(in_out) - 1)\n",
    "            down_modules.append(nn.ModuleList([\n",
    "                ConditionalResidualBlock1D(\n",
    "                    dim_in, dim_out, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups),\n",
    "                ConditionalResidualBlock1D(\n",
    "                    dim_out, dim_out, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups),\n",
    "                Downsample1d(dim_out) if not is_last else nn.Identity()\n",
    "            ]))\n",
    "\n",
    "        up_modules = nn.ModuleList([])\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (len(in_out) - 1)\n",
    "            up_modules.append(nn.ModuleList([\n",
    "                ConditionalResidualBlock1D(\n",
    "                    dim_out*2, dim_in, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups),\n",
    "                ConditionalResidualBlock1D(\n",
    "                    dim_in, dim_in, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups),\n",
    "                Upsample1d(dim_in) if not is_last else nn.Identity()\n",
    "            ]))\n",
    "\n",
    "        final_conv = nn.Sequential(\n",
    "            Conv1dBlock(start_dim, start_dim, kernel_size=kernel_size),\n",
    "            nn.Conv1d(start_dim, input_dim, 1),\n",
    "        )\n",
    "\n",
    "        self.diffusion_step_encoder = diffusion_step_encoder\n",
    "        self.up_modules = up_modules\n",
    "        self.down_modules = down_modules\n",
    "        self.final_conv = final_conv\n",
    "\n",
    "        print(\"number of parameters: {:e}\".format(\n",
    "            sum(p.numel() for p in self.parameters()))\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "            sample: torch.Tensor,\n",
    "            timestep: Union[torch.Tensor, float, int],\n",
    "            global_cond=None):\n",
    "        \"\"\"\n",
    "        x: (B,T,input_dim)\n",
    "        timestep: (B,) or int, diffusion step\n",
    "        global_cond: (B,global_cond_dim)\n",
    "        output: (B,T,input_dim)\n",
    "        \"\"\"\n",
    "        # (B,T,C)\n",
    "        sample = sample.moveaxis(-1,-2)\n",
    "        # (B,C,T)\n",
    "\n",
    "        # 1. time\n",
    "        timesteps = timestep\n",
    "        if not torch.is_tensor(timesteps):\n",
    "            # TODO: this requires sync between CPU and GPU. So try to pass timesteps as tensors if you can\n",
    "            timesteps = torch.tensor([timesteps], dtype=torch.long, device=sample.device)\n",
    "        elif torch.is_tensor(timesteps) and len(timesteps.shape) == 0:\n",
    "            timesteps = timesteps[None].to(sample.device)\n",
    "        # broadcast to batch dimension in a way that's compatible with ONNX/Core ML\n",
    "        timesteps = timesteps.expand(sample.shape[0])\n",
    "\n",
    "        global_feature = self.diffusion_step_encoder(timesteps)\n",
    "\n",
    "        if global_cond is not None:\n",
    "            global_feature = torch.cat([\n",
    "                global_feature, global_cond\n",
    "            ], axis=-1)\n",
    "\n",
    "        x = sample\n",
    "        h = []\n",
    "        for idx, (resnet, resnet2, downsample) in enumerate(self.down_modules):\n",
    "            x = resnet(x, global_feature)\n",
    "            x = resnet2(x, global_feature)\n",
    "            h.append(x)\n",
    "            x = downsample(x)\n",
    "\n",
    "        for mid_module in self.mid_modules:\n",
    "            x = mid_module(x, global_feature)\n",
    "\n",
    "        for idx, (resnet, resnet2, upsample) in enumerate(self.up_modules):\n",
    "            x = torch.cat((x, h.pop()), dim=1)\n",
    "            x = resnet(x, global_feature)\n",
    "            x = resnet2(x, global_feature)\n",
    "            x = upsample(x)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        # (B,C,T)\n",
    "        x = x.moveaxis(-1,-2)\n",
    "        # (B,T,C)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 6.541415e+07\n"
     ]
    }
   ],
   "source": [
    "#@markdown ### **Network Demo**\n",
    "\n",
    "# observation and action dimensions corrsponding to\n",
    "# the output of PushTEnv\n",
    "# obs_dim = 25\n",
    "# action_dim = 13\n",
    "\n",
    "obs_dim = 7\n",
    "action_dim = 4\n",
    "# parameters\n",
    "pred_horizon = 16\n",
    "obs_horizon = 2\n",
    "action_horizon = 8\n",
    "sample_size = 8\n",
    "\n",
    "# create network object\n",
    "noise_pred_net = ConditionalUnet1D(\n",
    "    input_dim=action_dim,\n",
    "    global_cond_dim=obs_dim*obs_horizon\n",
    ")\n",
    "\n",
    "# example inputs\n",
    "noised_action = torch.randn((1, pred_horizon, action_dim))\n",
    "obs = torch.zeros((1, obs_horizon, obs_dim))\n",
    "diffusion_iter = torch.zeros((1,))\n",
    "\n",
    "# the noise prediction network\n",
    "# takes noisy action, diffusion iteration and observation as input\n",
    "# predicts the noise added to action\n",
    "noise = noise_pred_net(\n",
    "    sample=noised_action,\n",
    "    timestep=diffusion_iter,\n",
    "    global_cond=obs.flatten(start_dim=1))\n",
    "\n",
    "# illustration of removing noise\n",
    "# the actual noise removal is performed by NoiseScheduler\n",
    "# and is dependent on the diffusion noise schedule\n",
    "denoised_action = noised_action - noise\n",
    "\n",
    "# for this demo, we use DDPMScheduler with 100 diffusion iterations\n",
    "num_diffusion_iters = 100\n",
    "noise_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=num_diffusion_iters,\n",
    "    # the choise of beta schedule has big impact on performance\n",
    "    # we found squared cosine works the best\n",
    "    beta_schedule='squaredcos_cap_v2',\n",
    "    # clip output to [-1,1] to improve stability\n",
    "    clip_sample=True,\n",
    "    # our network predicts noise (instead of denoised action)\n",
    "    prediction_type='epsilon'\n",
    ")\n",
    "\n",
    "# device transfer\n",
    "device = torch.device('cuda')\n",
    "_ = noise_pred_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown ### **Dataset**\n",
    "#@markdown\n",
    "#@markdown Defines `PushTStateDataset` and helper functions\n",
    "#@markdown\n",
    "#@markdown The dataset class\n",
    "#@markdown - Load data (obs, action) from a zarr storage\n",
    "#@markdown - Normalizes each dimension of obs and action to [-1,1]\n",
    "#@markdown - Returns\n",
    "#@markdown  - All possible segments with length `pred_horizon`\n",
    "#@markdown  - Pads the beginning and the end of each episode with repetition\n",
    "#@markdown  - key `obs`: shape (obs_horizon, obs_dim)\n",
    "#@markdown  - key `action`: shape (pred_horizon, action_dim)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "# from robodk import robolink    # RoboDK API\n",
    "from robomath import *   # Robot toolbox\n",
    "\n",
    "def distance(current, next):\n",
    "    distance = math.sqrt((next[0] - current[0])**2 + (next[1] - current[1])**2 + (next[2] - current[2])**2)\n",
    "    return distance\n",
    "\n",
    "def sampler(data, sample_size):\n",
    "    sam = []\n",
    "    for i in range(0, len(data)):\n",
    "        if i% sample_size == 0:\n",
    "            sam.append(data[i])\n",
    "    # print(sam)\n",
    "    return sam\n",
    "\n",
    "\n",
    "def euler_change(Gwxyz):\n",
    "    quaternion = np.array(Gwxyz)\n",
    "    euler_angles = []\n",
    "\n",
    "    for i in range(len(quaternion)):\n",
    "        # Create a Rotation object from the quaternion\n",
    "        pos_i = quaternion_2_pose(quaternion[i])\n",
    "        # print(\"pos_i\")\n",
    "        # print(pos_i)\n",
    "        eul_i = pose_2_xyzrpw(pos_i)\n",
    "        # print(\"eul_i\")\n",
    "        # print(eul_i)\n",
    "        # Convert to Euler angles (in radians)\n",
    "        euler_angles.append(eul_i[3:])  # 'xyz' specifies the order of rotations\n",
    "\n",
    "    return euler_angles\n",
    "\n",
    "def extract_data(result_dict, sample_size):\n",
    "\n",
    "\n",
    "    GXYZ, Gwxyz, SXYZ, Swxyz, BXYZ, Bwxyz, DXYZ, Dwxyz  = [], [], [], [], [], [], [], []\n",
    "    indexes = []\n",
    "    diff = []\n",
    "    mins = []\n",
    "    value_to_indexes = {}\n",
    "    indexes_in_list2 = []\n",
    "\n",
    "    for key in result_dict:\n",
    "        path_value = result_dict[key]['Path']\n",
    "        start = int(result_dict[key]['start_frame'])\n",
    "        end = int(result_dict[key]['end_frame'])\n",
    "\n",
    "        data  = pd.read_csv(path_value)\n",
    "        data = data.reset_index(drop=False)\n",
    "        data = data.drop(index =0)\n",
    "        data = data.drop(index =2)\n",
    "        data = data.reset_index(drop=True)\n",
    "\n",
    "        row1 = data.iloc[0]\n",
    "        row2 = data.iloc[1]\n",
    "        row3 = data.iloc[2]\n",
    "\n",
    "        combined_values = []\n",
    "        for a, b, c in zip(row1, row2, row3):\n",
    "            combined_values.append(str(a) + '_' + str(b) + '_' + str(c))\n",
    "\n",
    "        data.columns = combined_values\n",
    "        data = data.drop(index =0)\n",
    "        data = data.drop(index =1)\n",
    "        data = data.drop(index =2)\n",
    "        data = data.drop(data.columns[:2], axis=1)\n",
    "        # print(result_dict)\n",
    "        data = data.iloc[start:end]\n",
    "        data = data.dropna()\n",
    "        data = data.reset_index(drop=True)\n",
    "\n",
    "        # Regular expression pattern to match columns starting with 'gripper_1_Rotation'\n",
    "        pattern1 = re.compile(r'GRIPPER_2_Rotation')\n",
    "        pattern2 = re.compile(r'GRIPPER_2_Position')\n",
    "        pattern3 = re.compile(r'diff_scooper_2_2_Rotation')\n",
    "        pattern4 = re.compile(r'diff_scooper_2_2_Position')\n",
    "        pattern5 = re.compile(r'box3_Rotation')\n",
    "        pattern6 = re.compile(r'box3_Position')\n",
    "        pattern7 = re.compile(r'bucket_SC_Rotation')\n",
    "        pattern8 = re.compile(r'bucket_SC_Position')\n",
    "\n",
    "        # Filter columns using regex pattern and extract values into a list\n",
    "        a = data.filter(regex=pattern1).values.astype('float64').tolist()\n",
    "        a = sampler(a, sample_size)\n",
    "        b = data.filter(regex=pattern2).values.astype('float64').tolist()\n",
    "        b = sampler(b, sample_size)\n",
    "        c = data.filter(regex=pattern3).values.astype('float64').tolist()\n",
    "        c = sampler(c, sample_size)\n",
    "        d = data.filter(regex=pattern4).values.astype('float64').tolist()\n",
    "        d = sampler(d, sample_size)\n",
    "        e = data.filter(regex=pattern5).values.astype('float64').tolist()\n",
    "        e = sampler(e, sample_size)\n",
    "        f = data.filter(regex=pattern6).values.astype('float64').tolist()\n",
    "        f = sampler(f, sample_size)\n",
    "        g = data.filter(regex=pattern7).values.astype('float64').tolist()\n",
    "        g = sampler(g, sample_size)\n",
    "        h = data.filter(regex=pattern8).values.astype('float64').tolist()\n",
    "        h = sampler(h, sample_size)\n",
    "\n",
    "        for sublist in b:\n",
    "            y = sublist[0] \n",
    "            z= sublist[1]\n",
    "            x = sublist[2]\n",
    "            sublist[0] = x\n",
    "            sublist[1] = y\n",
    "            sublist[2] = z    \n",
    "\n",
    "        for sublist in d:\n",
    "            y = sublist[0]\n",
    "            z= sublist[1]\n",
    "            x = sublist[2]\n",
    "            sublist[0] = x\n",
    "            sublist[1] = y\n",
    "            sublist[2] = z  \n",
    "\n",
    "        for sublist in f:\n",
    "            y = sublist[0]\n",
    "            z= sublist[1]\n",
    "            x = sublist[2]\n",
    "            sublist[0] = x\n",
    "            sublist[1] = y\n",
    "            sublist[2] = z  \n",
    "\n",
    "        for sublist in h:\n",
    "            y = sublist[0]\n",
    "            z= sublist[1]\n",
    "            x = sublist[2]\n",
    "            sublist[0] = x\n",
    "            sublist[1] = y\n",
    "            sublist[2] = z  \n",
    "\n",
    "        for sublist in a:\n",
    "            y = sublist[0]\n",
    "            z = sublist[1]\n",
    "            x = sublist[2]\n",
    "            w = sublist[3]\n",
    "            sublist[0] = w\n",
    "            sublist[1] = x\n",
    "            sublist[2] = y    \n",
    "            sublist[3] = z    \n",
    "\n",
    "        a = euler_change(a)\n",
    "        # print(a)\n",
    "\n",
    "        for sublist in c:\n",
    "            y = sublist[0]\n",
    "            z = sublist[1]\n",
    "            x = sublist[2]\n",
    "            w = sublist[3]\n",
    "            sublist[0] = w\n",
    "            sublist[1] = x\n",
    "            sublist[2] = y    \n",
    "            sublist[3] = z   \n",
    "\n",
    "        c = euler_change(c)\n",
    "\n",
    "        for sublist in e:\n",
    "            y = sublist[0]\n",
    "            z = sublist[1]\n",
    "            x = sublist[2]\n",
    "            w = sublist[3]\n",
    "            sublist[0] = w\n",
    "            sublist[1] = x\n",
    "            sublist[2] = y    \n",
    "            sublist[3] = z  \n",
    "\n",
    "        e = euler_change(e)\n",
    "\n",
    "        for sublist in g:\n",
    "            y = sublist[0]\n",
    "            z = sublist[1]\n",
    "            x = sublist[2]\n",
    "            w = sublist[3]\n",
    "            sublist[0] = w\n",
    "            sublist[1] = x\n",
    "            sublist[2] = y    \n",
    "            sublist[3] = z\n",
    "\n",
    "        g = euler_change(g)\n",
    "\n",
    "        GXYZ.extend(b)\n",
    "        indexes.append(len(GXYZ))\n",
    "        Gwxyz.extend(a)\n",
    "        SXYZ.extend(d)\n",
    "        Swxyz.extend(c)\n",
    "        BXYZ.extend(f)\n",
    "        Bwxyz.extend(e)\n",
    "        DXYZ.extend(h)\n",
    "        Dwxyz.extend(g)\n",
    "\n",
    "\n",
    "    for i in range(min(len(GXYZ), len(BXYZ))):\n",
    "        diff_s = distance(GXYZ[i], BXYZ[i])\n",
    "        diff.append(diff_s)\n",
    "\n",
    "    GA = np.full_like(diff, -1)\n",
    "    min_values = sorted(set(diff))\n",
    "\n",
    "    for index, value in enumerate(min_values):\n",
    "        if value < 0.01:\n",
    "            mins.append(value)\n",
    "            \n",
    "    # Populate the dictionary with list2 values and their indexes\n",
    "    for index, value in enumerate(diff):\n",
    "        if value in value_to_indexes:\n",
    "            value_to_indexes[value].append(index)\n",
    "        else:\n",
    "            value_to_indexes[value] = [index]\n",
    "\n",
    "    # Find indexes in list2 corresponding to values in list1\n",
    "    for value in mins:\n",
    "        if value in value_to_indexes:\n",
    "            indexes_in_list2.extend(value_to_indexes[value])\n",
    "\n",
    "    for i in range (min(indexes_in_list2), max(indexes_in_list2)+1):\n",
    "        GA[i] = 1\n",
    "\n",
    "    # return  b, a, d, c, f, e, h, g\n",
    "    return GXYZ, Gwxyz, SXYZ, Swxyz, BXYZ, Bwxyz, DXYZ, Dwxyz, indexes, GA.tolist()\n",
    "\n",
    "def generate_sequential_random_sequence(max_value):\n",
    "    random_sequence = []\n",
    "    current_value = 0\n",
    "    \n",
    "    while current_value < max_value:\n",
    "        # Generate a random increment (not exceeding 1000 to ensure it doesn't jump too far)\n",
    "        increment = random.randint(1, min(200, max_value - current_value))\n",
    "        current_value += increment\n",
    "        random_sequence.append(current_value)\n",
    "    \n",
    "    # If the last value is more than max_value, remove it\n",
    "    if random_sequence[-1] > max_value:\n",
    "        random_sequence.pop()\n",
    "    \n",
    "    return random_sequence\n",
    "\n",
    "def create_sample_indices(\n",
    "        episode_ends:np.ndarray, sequence_length:int,\n",
    "        pad_before: int=0, pad_after: int=0):\n",
    "    indices = []\n",
    "    for i in range(len(episode_ends)):\n",
    "        start_idx = 0\n",
    "        if i > 0:\n",
    "            start_idx = episode_ends[i-1]\n",
    "        end_idx = episode_ends[i]\n",
    "        episode_length = end_idx - start_idx\n",
    "\n",
    "        min_start = -pad_before\n",
    "        # print(\"Start min\",min_start)\n",
    "        max_start = episode_length - sequence_length + pad_after\n",
    "        # print(\"Start max\",max_start)\n",
    "\n",
    "        # range stops one idx before end\n",
    "        for idx in range(min_start, max_start+1):\n",
    "            buffer_start_idx = max(idx, 0) + start_idx\n",
    "            buffer_end_idx = min(idx+sequence_length, episode_length) + start_idx\n",
    "            start_offset = buffer_start_idx - (idx+start_idx)\n",
    "            end_offset = (idx+sequence_length+start_idx) - buffer_end_idx\n",
    "            sample_start_idx = 0 + start_offset\n",
    "            sample_end_idx = sequence_length - end_offset\n",
    "            indices.append([\n",
    "                buffer_start_idx, buffer_end_idx,\n",
    "                sample_start_idx, sample_end_idx])\n",
    "    indices = np.array(indices)\n",
    "    return indices\n",
    "\n",
    "\n",
    "def sample_sequence(train_data, sequence_length,\n",
    "                    buffer_start_idx, buffer_end_idx,\n",
    "                    sample_start_idx, sample_end_idx):\n",
    "    result = dict()\n",
    "    for key, input_arr in train_data.items():\n",
    "        sample = input_arr[buffer_start_idx:buffer_end_idx]\n",
    "        data = sample\n",
    "        if (sample_start_idx > 0) or (sample_end_idx < sequence_length):\n",
    "            data = np.zeros(\n",
    "                shape=(sequence_length,) + input_arr.shape[1:],\n",
    "                dtype=input_arr.dtype)\n",
    "            if sample_start_idx > 0:\n",
    "                data[:sample_start_idx] = sample[0]\n",
    "            if sample_end_idx < sequence_length:\n",
    "                data[sample_end_idx:] = sample[-1]\n",
    "            data[sample_start_idx:sample_end_idx] = sample\n",
    "        result[key] = data\n",
    "    return result\n",
    "\n",
    "# normalize data\n",
    "def get_data_stats(data):\n",
    "    data = data.reshape(-1,data.shape[-1])\n",
    "    stats = {\n",
    "        'min': np.min(data, axis=0),\n",
    "        'max': np.max(data, axis=0)\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "def normalize_data(data, stats):\n",
    "    # nomalize to [0,1]\n",
    "    ndata = (data - stats['min']) / (stats['max'] - stats['min'])\n",
    "    # normalize to [-1, 1]\n",
    "    ndata = ndata * 2 - 1\n",
    "    return ndata\n",
    "\n",
    "def unnormalize_data(ndata, stats):\n",
    "    ndata = (ndata + 1) / 2\n",
    "    data = ndata * (stats['max'] - stats['min']) + stats['min']\n",
    "    return data\n",
    "\n",
    "# dataset\n",
    "class RealStateDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset,  base_path,\n",
    "                 pred_horizon, obs_horizon, action_horizon, sample_size):\n",
    "        \n",
    "        # read from zarr dataset\n",
    "        list = dataset\n",
    "        # Base path\n",
    "        collums = list.columns\n",
    "\n",
    "        result_dict = {}\n",
    "        count = 0\n",
    "        for i in range(len(list)):\n",
    "            if list[collums[3]][i] == 'accept':\n",
    "                result_dict[count] = {\n",
    "                    'Path': base_path + str(list[collums[0]][i]) + '.csv',\n",
    "                    'start_frame': list[collums[1]][i],\n",
    "                    'end_frame': list[collums[2]][i],\n",
    "                    'Note': list[collums[4]][i]\n",
    "                }\n",
    "                count += 1\n",
    "\n",
    "        # for key in result_dict:\n",
    "        GXYZ, Gwxyz, SXYZ, Swxyz, BXYZ, Bwxyz, DXYZ, Dwxyz, index , GA = extract_data(result_dict, sample_size)\n",
    "\n",
    "        action = []\n",
    "        obs = []\n",
    "        for i in range(len(GXYZ)):\n",
    "            a = []\n",
    "            # a = Gwxyz[i] + GXYZ[i] + Swxyz[i] + SXYZ[i]\n",
    "            a.extend(GXYZ[i])\n",
    "            # print(GXYZ[i])\n",
    "            # print(a)\n",
    "            a.append(GA[i])\n",
    "            # print(a)\n",
    "            # b = Gwxyz[i] + GXYZ[i] + Swxyz[i] + SXYZ[i] + Dwxyz[i] + DXYZ[i] + Bwxyz[i] + BXYZ[i]\n",
    "            b =  GXYZ[i] + BXYZ[i]\n",
    "            b.append(GA[i])\n",
    "            # print(b)\n",
    "            action.append(a)\n",
    "            obs.append(b)\n",
    "\n",
    "    # All demonstration episodes are concatinated in the first dimension N\n",
    "        action = np.array(action, dtype=np.float64)\n",
    "        obs = np.array(obs, dtype=np.float64)\n",
    "        train_data = {\n",
    "            # (N, action_dim)\n",
    "            'action': action[:],\n",
    "            # (N, obs_dim)\n",
    "            'obs': obs[:]\n",
    "        }\n",
    "\n",
    "        # Marks one-past the last index for each episode\n",
    "        # episode_ends = generate_sequential_random_sequence(3585)\n",
    "        episode_len = index\n",
    "        print(episode_len)\n",
    "\n",
    "        # compute start and end of each state-action sequence\n",
    "        # also handles padding\n",
    "        indices = create_sample_indices(\n",
    "            episode_ends=episode_len,\n",
    "            sequence_length=pred_horizon,\n",
    "            # add padding such that each timestep in the dataset are seen\n",
    "            pad_before=obs_horizon-1,\n",
    "            pad_after=action_horizon-1)\n",
    "        \n",
    "        # print(indices.shape)\n",
    "        # print(len(indices))\n",
    "        # print(indices[:5])\n",
    "        # compute statistics and normalized data to [-1,1]\n",
    "        stats = dict()\n",
    "        normalized_train_data = dict()\n",
    "        for key, data in train_data.items():\n",
    "            stats[key] = get_data_stats(data)\n",
    "            normalized_train_data[key] = normalize_data(data, stats[key])\n",
    "\n",
    "        self.indices = indices\n",
    "        self.stats = stats\n",
    "        self.normalized_train_data = normalized_train_data\n",
    "        self.pred_horizon = pred_horizon\n",
    "        self.action_horizon = action_horizon\n",
    "        self.obs_horizon = obs_horizon\n",
    "\n",
    "    def __len__(self):\n",
    "        # all possible segments of the dataset\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get the start/end indices for this datapoint\n",
    "        buffer_start_idx, buffer_end_idx, \\\n",
    "            sample_start_idx, sample_end_idx = self.indices[idx]\n",
    "\n",
    "        # get nomralized data using these indices\n",
    "        # print(\"gett item\")\n",
    "        nsample = sample_sequence(\n",
    "            train_data=self.normalized_train_data,\n",
    "            sequence_length=self.pred_horizon,\n",
    "            buffer_start_idx=buffer_start_idx,\n",
    "            buffer_end_idx=buffer_end_idx,\n",
    "            sample_start_idx=sample_start_idx,\n",
    "            sample_end_idx=sample_end_idx\n",
    "        )\n",
    "\n",
    "        # discard unused observations\n",
    "        nsample['obs'] = nsample['obs'][:self.obs_horizon,:]\n",
    "        return nsample\n",
    "    \n",
    "# dataset\n",
    "class PushTStateDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_path,\n",
    "                 pred_horizon, obs_horizon, action_horizon):\n",
    "\n",
    "        # read from zarr dataset\n",
    "        dataset_root = zarr.open(dataset_path, 'r')\n",
    "        # All demonstration episodes are concatinated in the first dimension N\n",
    "        train_data = {\n",
    "            # (N, action_dim)\n",
    "            'action': dataset_root['data']['action'][:],\n",
    "            # (N, obs_dim)\n",
    "            'obs': dataset_root['data']['state'][:]\n",
    "        }\n",
    "        # Marks one-past the last index for each episode\n",
    "        episode_ends = dataset_root['meta']['episode_ends'][:]\n",
    "\n",
    "        # compute start and end of each state-action sequence\n",
    "        # also handles padding\n",
    "        indices = create_sample_indices(\n",
    "            episode_ends=episode_ends,\n",
    "            sequence_length=pred_horizon,\n",
    "            # add padding such that each timestep in the dataset are seen\n",
    "            pad_before=obs_horizon-1,\n",
    "            pad_after=action_horizon-1)\n",
    "\n",
    "        # compute statistics and normalized data to [-1,1]\n",
    "        stats = dict()\n",
    "        normalized_train_data = dict()\n",
    "        for key, data in train_data.items():\n",
    "            stats[key] = get_data_stats(data)\n",
    "            normalized_train_data[key] = normalize_data(data, stats[key])\n",
    "\n",
    "        self.indices = indices\n",
    "        self.stats = stats\n",
    "        self.normalized_train_data = normalized_train_data\n",
    "        self.pred_horizon = pred_horizon\n",
    "        self.action_horizon = action_horizon\n",
    "        self.obs_horizon = obs_horizon\n",
    "\n",
    "    def __len__(self):\n",
    "        # all possible segments of the dataset\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get the start/end indices for this datapoint\n",
    "        buffer_start_idx, buffer_end_idx, \\\n",
    "            sample_start_idx, sample_end_idx = self.indices[idx]\n",
    "\n",
    "        # get nomralized data using these indices\n",
    "        nsample = sample_sequence(\n",
    "            train_data=self.normalized_train_data,\n",
    "            sequence_length=self.pred_horizon,\n",
    "            buffer_start_idx=buffer_start_idx,\n",
    "            buffer_end_idx=buffer_end_idx,\n",
    "            sample_start_idx=sample_start_idx,\n",
    "            sample_end_idx=sample_end_idx\n",
    "        )\n",
    "\n",
    "        # discard unused observations\n",
    "        nsample['obs'] = nsample['obs'][:self.obs_horizon,:]\n",
    "        return nsample\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch['obs'].shape: torch.Size([256, 2, 5])\n",
      "batch['action'].shape torch.Size([256, 16, 2])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# download demonstration data from Google Drive\n",
    "dataset_path = \"pusht_cchi_v7_replay.zarr.zip\"\n",
    "if not os.path.isfile(dataset_path):\n",
    "    id = \"1KY1InLurpMvJDRb14L9NlXT_fEsCvVUq&confirm=t\"\n",
    "    gdown.download(id=id, output=dataset_path, quiet=False)\n",
    "\n",
    "# parameters\n",
    "pred_horizon = 16\n",
    "obs_horizon = 2\n",
    "action_horizon = 8\n",
    "#|o|o|                             observations: 2\n",
    "#| |a|a|a|a|a|a|a|a|               actions executed: 8\n",
    "#|p|p|p|p|p|p|p|p|p|p|p|p|p|p|p|p| actions predicted: 16\n",
    "\n",
    "# create dataset from file\n",
    "dataset = PushTStateDataset(\n",
    "    dataset_path=dataset_path,\n",
    "    pred_horizon=pred_horizon,\n",
    "    obs_horizon=obs_horizon,\n",
    "    action_horizon=action_horizon\n",
    ")\n",
    "# save training data statistics (min, max) for each dim\n",
    "stats = dataset.stats\n",
    "\n",
    "# create dataloader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    num_workers=1,\n",
    "    shuffle=True,\n",
    "    # accelerate cpu-gpu transfer\n",
    "    pin_memory=True,\n",
    "    # don't kill worker process afte each epoch\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "# visualize data in batch\n",
    "batch = next(iter(dataloader))\n",
    "print(\"batch['obs'].shape:\", batch['obs'].shape)\n",
    "print(\"batch['action'].shape\", batch['action'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HANDOVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167, 317, 470, 618, 748, 896, 1028, 1170, 1315, 1447, 1579, 1719, 1851, 1999, 2151, 2272, 2416, 2561, 2693, 2838, 2958, 3080, 3212, 3344, 3471, 3609, 3726, 3856, 3978, 4108, 4245, 4372, 4488, 4620, 4746, 4901, 5041, 5186, 5342, 5474, 5610, 5728, 5843, 5993, 6101, 6216, 6334, 6473, 6596, 6709, 6836, 6964, 7095, 7243, 7357, 7482, 7605, 7725, 7848, 7971, 8096, 8212, 8331, 8460, 8582, 8709, 8863, 9005, 9132, 9237, 9355, 9469, 9588, 9678, 9802, 9937, 10065, 10202, 10329, 10447, 10567, 10711, 10831, 10959, 11086, 11207, 11308, 11434, 11567, 11692, 11816, 11931, 12055, 12188, 12307, 12420, 12563, 12681, 12808, 12924, 13042, 13154, 13274, 13393, 13559, 13676, 13786, 13903, 14026, 14169, 14299, 14421, 14539, 14658, 14770, 14894, 15012, 15137, 15251, 15388, 15530, 15657, 15796, 15930, 16088, 16225]\n",
      "batch['obs'].shape: torch.Size([256, 2, 7])\n",
      "batch['action'].shape torch.Size([256, 16, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create dataset from file\n",
    "path_name = \"/home/cam/Documents/test_mujoco_2/Archive/Supporting Data - Sheet1.csv\"\n",
    "base_path = \"/home/cam/Documents/test_mujoco_2/Archive/sean & Li 2 exports/\"\n",
    "data = pd.read_csv(path_name)\n",
    "split_index = int(len(data) * 0.8)\n",
    "\n",
    "# Split DataFrame\n",
    "train_df = data.iloc[:split_index]\n",
    "test_df = data.iloc[split_index:]\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dataset_train = RealStateDataset(\n",
    "    dataset=train_df,\n",
    "    base_path=base_path,\n",
    "    pred_horizon=pred_horizon,\n",
    "    obs_horizon=obs_horizon,\n",
    "    action_horizon=action_horizon,\n",
    "    sample_size=sample_size\n",
    ")\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=256,\n",
    "    num_workers=1,\n",
    "    shuffle=True,\n",
    "    # accelerate cpu-gpu transfer\n",
    "    pin_memory=True,\n",
    "    # don't kill worker process afte each epoch\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "\n",
    "batch = next(iter(dataloader_train))\n",
    "print(\"batch['obs'].shape:\", batch['obs'].shape)\n",
    "print(\"batch['action'].shape\", batch['action'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataloaders = dataloader ## PUSH T data loader\n",
    "\n",
    "dataloaders = dataloader_train ## handoverTask data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders = dataloader \n",
    "dataloaders = dataloader_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 1/200 [02:13<7:22:43, 133.48s/it, loss=0.847]"
     ]
    }
   ],
   "source": [
    "#@markdown ### **Training**\n",
    "#@markdown\n",
    "#@markdown Takes about an hour. If you don't want to wait, skip to the next cell\n",
    "#@markdown to load pre-trained weights\n",
    "import os\n",
    "import time\n",
    "\n",
    "num_epochs = 200\n",
    "checkpoint_dir = 'checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_interval = 3600\n",
    "last_checkpoint_time = time.time()\n",
    "# Exponential Moving Average\n",
    "# accelerates training and improves stability\n",
    "# holds a copy of the model weights\n",
    "ema = EMAModel(\n",
    "    model=noise_pred_net,\n",
    "    power=0.75)\n",
    "\n",
    "# Standard ADAM optimizer\n",
    "# Note that EMA parametesr are not optimized\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=noise_pred_net.parameters(),\n",
    "    lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "# Cosine LR schedule with linear warmup\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='cosine',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=200,\n",
    "    num_training_steps=len(dataloaders) * num_epochs\n",
    ")\n",
    "\n",
    "with tqdm(range(num_epochs), desc='Epoch') as tglobal:\n",
    "    # epoch loop\n",
    "    epoch_loss = []\n",
    "    batch_loss_per_epoch = []\n",
    "\n",
    "    for epoch_idx in tglobal:\n",
    "        batch_loss = []\n",
    "        batch_noise = []\n",
    "        # batch loop\n",
    "        with tqdm(dataloaders, desc='Batch', leave=False) as tepoch:\n",
    "\n",
    "            for nbatch in tepoch:\n",
    "                # data normalized in dataset\n",
    "                # device transfer\n",
    "                # nobs = nbatch['obs'].to(device)\n",
    "                # naction = nbatch['action'].to(device)\n",
    "                nobs = nbatch['obs']\n",
    "                naction = nbatch['action']\n",
    "                B = nobs.shape[0]\n",
    "\n",
    "                # observation as FiLM conditioning\n",
    "                # (B, obs_horizon, obs_dim)\n",
    "                obs_cond = nobs[:,:obs_horizon,:]\n",
    "                # (B, obs_horizon * obs_dim)\n",
    "                obs_cond = obs_cond.flatten(start_dim=1).float().to(device)\n",
    "                # print(obs_cond.type())\n",
    "\n",
    "                # sample noise to add to actions\n",
    "                # noise = torch.randn(naction.shape, device=device)\n",
    "                noise = torch.randn(naction.shape)\n",
    "\n",
    "                # sample a diffusion iteration for each data point\n",
    "                # timesteps = torch.randint(\n",
    "                #     0, noise_scheduler.config.num_train_timesteps,\n",
    "                #     (B,), device=device\n",
    "                # ).long()\n",
    "\n",
    "                timesteps = torch.randint(\n",
    "                    0, noise_scheduler.config.num_train_timesteps,\n",
    "                    (B,)\n",
    "                ).long()\n",
    "\n",
    "                # add noise to the clean images according to the noise magnitude at each diffusion iteration\n",
    "                # (this is the forward diffusion process)\n",
    "                noisy_actions = noise_scheduler.add_noise(\n",
    "                    naction, noise, timesteps)\n",
    "                \n",
    "                noise = noise.to(device)\n",
    "                \n",
    "                timesteps = timesteps.to(device)\n",
    "\n",
    "                # print(noisy_actions.type())\n",
    "                noisy_actions = noisy_actions.type(torch.FloatTensor).to(device)\n",
    "                # print(noisy_actions.type())\n",
    "\n",
    "                # predict the noise residual\n",
    "                noise_pred = noise_pred_net(\n",
    "                    noisy_actions, timesteps, global_cond=obs_cond)\n",
    "                batch_noise.append(noise_pred)\n",
    "\n",
    "                # L2 loss\n",
    "                loss = nn.functional.mse_loss(noise_pred, noise)\n",
    "\n",
    "                # optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                # step lr scheduler every batch\n",
    "                # this is different from standard pytorch behavior\n",
    "                lr_scheduler.step()\n",
    "\n",
    "                # update Exponential Moving Average of the model weights\n",
    "                ema.step(noise_pred_net)\n",
    "                # print(ema.state_dict)\n",
    "\n",
    "                # logging\n",
    "                loss_cpu = loss.item()\n",
    "                batch_loss.append(loss_cpu)\n",
    "                tepoch.set_postfix(loss=loss_cpu)\n",
    "\n",
    "        # save checkpoint\n",
    "        # went to the emma model library and added state_dict to the model\n",
    "        current_time = time.time()\n",
    "        if current_time - last_checkpoint_time > checkpoint_interval:\n",
    "        # if epoch_idx == 2:\n",
    "            # Save model checkpoint\n",
    "            # checkpoint_path = os.path.join(checkpoint_dir, f'BOX_GRIP_checkpoint_epoch_{epoch_idx}.pth')\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'T_checkpoint_epoch_{epoch_idx}.pth')\n",
    "\n",
    "            torch.save({\n",
    "                'epoch': epoch_idx,\n",
    "                'model_state_dict': noise_pred_net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "                'ema_state_dict': ema.state_dict,\n",
    "                'loss': loss.cpu().detach().numpy(),\n",
    "            }, checkpoint_path)\n",
    "            print(f'Checkpoint saved at epoch {epoch_idx}')\n",
    "            last_checkpoint_time = current_time\n",
    "        elif epoch_idx == num_epochs:\n",
    "            # Save model checkpoint\n",
    "            # checkpoint_path = os.path.join(checkpoint_dir, f'BOX_GRIP_checkpoint_epoch_{epoch_idx}.pth')\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'T_checkpoint_epoch_{epoch_idx}.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch_idx,\n",
    "                'model_state_dict': noise_pred_net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "                'ema_state_dict': ema.state_dict,\n",
    "                'loss': loss.cpu().detach().numpy(),\n",
    "            }, checkpoint_path)\n",
    "            print(f'Checkpoint saved at epoch {epoch_idx}')\n",
    "            last_checkpoint_time = current_time\n",
    "            \n",
    "        tglobal.set_postfix(loss=np.mean(batch_loss))\n",
    "        epoch_loss.append(np.mean(batch_loss))\n",
    "        batch_loss_per_epoch.append(batch_loss)\n",
    "\n",
    "# Weights of the EMA model\n",
    "# is used for inference\n",
    "ema_noise_pred_net = noise_pred_net\n",
    "# ema.copy_to(ema_noise_pred_net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure and axis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "flatten_loss = np.array(batch_loss_per_epoch)\n",
    "\n",
    "flatten_loss = flatten_loss.flatten()\n",
    "# Define subplots correctly\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot for the first subplot (ax1)\n",
    "ax1.plot(flatten_loss, marker='o', linestyle='-', color='b', label='Values')\n",
    "\n",
    "# Customize the first subplot (ax1)\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Value')\n",
    "ax1.set_title('Batch Loss for all Epochs')\n",
    "ax1.grid(True)\n",
    "# ax1.legend()\n",
    "\n",
    "# Plot for the second subplot (ax2)\n",
    "ax2.plot(epoch_loss, marker='o', linestyle='-', color='b', label='Values')\n",
    "\n",
    "# Customize the second subplot (ax2)\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Value')\n",
    "ax2.set_title('Epoch Loss')\n",
    "ax2.grid(True)\n",
    "# ax2.legend()\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# # Load model state\n",
    "# noise_pred_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# # Load optimizer state\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# # Load LR scheduler state (if applicable)\n",
    "# lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
    "\n",
    "# # Load EMA model state\n",
    "# ema.load_state_dict(checkpoint['ema_state_dict'])\n",
    "\n",
    "# # Optionally, retrieve other information such as epoch and loss\n",
    "# epoch_loaded = checkpoint['epoch']\n",
    "# loss_loaded = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Hand over data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = test_df\n",
    "# Base path\n",
    "base_path = \"/home/cam/Documents/test_mujoco_2/Archive/sean & Li 2 exports/\"\n",
    "collums = list.columns\n",
    "\n",
    "result_dict = {}\n",
    "count = 0\n",
    "for i in range(len(list)):\n",
    "    if list[collums[3]][i] == 'accept':\n",
    "        result_dict[count] = {\n",
    "            'Path': base_path + str(list[collums[0]][i]) + '.csv',\n",
    "            'start_frame': list[collums[1]][i],\n",
    "            'end_frame': list[collums[2]][i],\n",
    "            'Note': list[collums[4]][i]\n",
    "        }\n",
    "        count += 1\n",
    "\n",
    "# for key in result_dict:\n",
    "GXYZ, Gwxyz, SXYZ, Swxyz, BXYZ, Bwxyz, DXYZ, Dwxyz, index , GA = extract_data(result_dict, sample_size)\n",
    "\n",
    "action = []\n",
    "obs = []\n",
    "    \n",
    "for i in range(len(GXYZ)):\n",
    "    a = Gwxyz[i] + GXYZ[i]\n",
    "    a.append(GA[i])\n",
    "    b = Gwxyz[i] + GXYZ[i] + Bwxyz[i] + BXYZ[i]\n",
    "    b.append(GA[i])\n",
    "    action.append(a)\n",
    "    obs.append(b)\n",
    "\n",
    "# All demonstration episodes are concatinated in the first dimension N\n",
    "action = np.array(action, dtype=np.float64)\n",
    "obs = np.array(obs, dtype=np.float64)\n",
    "test_data = {\n",
    "    # (N, action_dim)\n",
    "    'action': action[:],\n",
    "    # (N, obs_dim)\n",
    "    'obs': obs[:]\n",
    "}\n",
    "\n",
    "# Marks one-past the last index for each episode\n",
    "# episode_ends = generate_sequential_random_sequence(3585)\n",
    "episode_ends = index\n",
    "print(type(episode_ends))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_obs = []\n",
    "splits_action = []\n",
    "previous_index = 0\n",
    "\n",
    "# Iterate through index_ranges and slice combined_list accordingly\n",
    "for index in episode_ends:\n",
    "    splits_obs.append(test_data['obs'][previous_index:index + 1])  # Include index itself in the slice\n",
    "    splits_action.append(test_data['action'][previous_index:index + 1])\n",
    "    previous_index = index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Handover data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = train_df\n",
    "# Base path\n",
    "base_path = \"/home/cam/Documents/test_mujoco_2/Archive/sean & Li 2 exports/\"\n",
    "collums = list.columns\n",
    "\n",
    "result_dict = {}\n",
    "count = 0\n",
    "for i in range(len(list)):\n",
    "    if list[collums[3]][i] == 'accept':\n",
    "        result_dict[count] = {\n",
    "            'Path': base_path + str(list[collums[0]][i]) + '.csv',\n",
    "            'start_frame': list[collums[1]][i],\n",
    "            'end_frame': list[collums[2]][i],\n",
    "            'Note': list[collums[4]][i]\n",
    "        }\n",
    "        count += 1\n",
    "\n",
    "# for key in result_dict:\n",
    "GXYZ, Gwxyz, SXYZ, Swxyz, BXYZ, Bwxyz, DXYZ, Dwxyz, index , GA = extract_data(result_dict, sample_size)\n",
    "\n",
    "action = []\n",
    "obs = []\n",
    "    \n",
    "for i in range(len(GXYZ)):\n",
    "    a = Gwxyz[i] + GXYZ[i] + Swxyz[i] + SXYZ[i]\n",
    "    a.append(GA[i])\n",
    "    b = Gwxyz[i] + GXYZ[i] + Swxyz[i] + SXYZ[i] + Dwxyz[i] + DXYZ[i] + Bwxyz[i] + BXYZ[i]\n",
    "    b.append(GA[i])\n",
    "    action.append(a)\n",
    "    obs.append(b)\n",
    "\n",
    "# All demonstration episodes are concatinated in the first dimension N\n",
    "action = np.array(action, dtype=np.float64)\n",
    "obs = np.array(obs, dtype=np.float64)\n",
    "val_data = {\n",
    "    # (N, action_dim)\n",
    "    'action': action[:],\n",
    "    # (N, obs_dim)\n",
    "    'obs': obs[:]\n",
    "}\n",
    "\n",
    "# Marks one-past the last index for each episode\n",
    "# episode_ends = generate_sequential_random_sequence(3585)\n",
    "episode_ends = index\n",
    "print(type(episode_ends))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_val_obs = []\n",
    "splits_val_action = []\n",
    "previous_index = 0\n",
    "\n",
    "# Iterate through index_ranges and slice combined_list accordingly\n",
    "for index in episode_ends:\n",
    "    splits_val_obs.append(val_data['obs'][previous_index:index + 1])  # Include index itself in the slice\n",
    "    splits_val_action.append(val_data['action'][previous_index:index + 1])\n",
    "    previous_index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(splits_val_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orignal PusT data task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "        # read from zarr dataset\n",
    "dataset_root = zarr.open(dataset_path, 'r')\n",
    "# All demonstration episodes are concatinated in the first dimension N\n",
    "train_data = {\n",
    "    # (N, action_dim)\n",
    "    'action': dataset_root['data']['action'][:],\n",
    "    # (N, obs_dim)\n",
    "    'obs': dataset_root['data']['state'][:]\n",
    "}\n",
    "\n",
    "episode_ends = dataset_root['meta']['episode_ends'][:]\n",
    "\n",
    "splits_T_obs = []\n",
    "split_T_action = []\n",
    "previous_index = 0\n",
    "\n",
    "# Iterate through index_ranges and slice combined_list accordingly\n",
    "for index in episode_ends:\n",
    "    splits_T_obs.append(train_data['obs'][previous_index:index + 1])  # Include index itself in the slice\n",
    "    split_T_action.append(train_data['action'][previous_index:index + 1])  # Include index itself in the slice\n",
    "    previous_index = index + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recheck which datatset are you using because split is getting overwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = {}\n",
    "for j in range(len(episode_ends)):\n",
    "    # get first observation\n",
    "    com_obs = splits_obs[j]\n",
    "    obs = splits_obs[j][0]\n",
    "    actions_test = splits_action[j]\n",
    "    # max_steps = len(test_data['action'])\n",
    "    max_steps = len(actions_test)\n",
    "    stats = dataset.stats\n",
    "    # keep a queue of last 2 steps of observations\n",
    "    obs_deque = collections.deque(\n",
    "        [obs] * obs_horizon, maxlen=obs_horizon)\n",
    "\n",
    "    # save visualization and rewards\n",
    "    done = False\n",
    "    step_idx = 0\n",
    "    traj = []\n",
    "    with tqdm(total=max_steps, desc=\"Eval\") as pbar:\n",
    "        while not done:\n",
    "            B = 1\n",
    "            # stack the last obs_horizon (2) number of observations\n",
    "            obs_seq = np.stack(obs_deque)\n",
    "            # print(\"Obs_sep -\",obs_seq)\n",
    "            # normalize observation\n",
    "            nobs = normalize_data(obs_seq, stats=stats['obs'])\n",
    "            # print(nobs)\n",
    "            # device transfer\n",
    "            nobs = torch.from_numpy(nobs).to(device, dtype=torch.float32)\n",
    "            # infer action\n",
    "            with torch.no_grad():\n",
    "                # reshape observation to (B,obs_horizon*obs_dim)\n",
    "                obs_cond = nobs.unsqueeze(0).flatten(start_dim=1)\n",
    "                # print(obs_cond.shape)\n",
    "\n",
    "                # initialize action from Guassian noise\n",
    "                noisy_action = torch.randn(\n",
    "                    (B, pred_horizon, action_dim), device=device)\n",
    "                naction = noisy_action\n",
    "\n",
    "                # init scheduler\n",
    "                noise_scheduler.set_timesteps(num_diffusion_iters)\n",
    "\n",
    "                for k in noise_scheduler.timesteps:\n",
    "                    # predict noise\n",
    "                    noise_pred = ema_noise_pred_net(\n",
    "                        sample=naction,\n",
    "                        timestep=k,\n",
    "                        global_cond=obs_cond\n",
    "                    )\n",
    "\n",
    "                    # inverse diffusion step (remove noise)\n",
    "                    naction = noise_scheduler.step(\n",
    "                        model_output=noise_pred,\n",
    "                        timestep=k,\n",
    "                        sample=naction\n",
    "                    ).prev_sample\n",
    "\n",
    "            # unnormalize action\n",
    "            naction = naction.detach().to('cpu').numpy()\n",
    "            # (B, pred_horizon, action_dim)\n",
    "            naction = naction[0]\n",
    "            action_pred = unnormalize_data(naction, stats=stats['action'])\n",
    "\n",
    "            # only take action_horizon number of actions\n",
    "            start = obs_horizon - 1\n",
    "            end = start + action_horizon\n",
    "            action = action_pred[start:end,:]\n",
    "            # print(action[0])\n",
    "            # print(actions_test[0])\n",
    "            traj.extend(action)\n",
    "            losses = []\n",
    "\n",
    "            # if len(action) <= len(actions_test):\n",
    "            #     lenths = len(action)\n",
    "\n",
    "            # else :\n",
    "            #     lenths = len(actions_test)\n",
    "                \n",
    "            for i in range(len(action)):\n",
    "                # loss\n",
    "                # print(\"Action_pred -\",action[i])\n",
    "                # print(\"Action_orignal -\",actions_test[i])\n",
    "                # print(\"Obs_added -\",com_obs[i])\n",
    "                if len(action) > len(actions_test):\n",
    "                    done = True\n",
    "                if done:\n",
    "                    break\n",
    "                loss_test = nn.functional.mse_loss(torch.tensor(action[i]), torch.tensor(actions_test[i]))\n",
    "                obs_deque.append(com_obs[i])\n",
    "                losses.append(loss_test.item())\n",
    "                # update progress bar\n",
    "                step_idx += 1\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(loss=np.mean(losses))\n",
    "                # print(i)\n",
    "                if step_idx > max_steps:\n",
    "                    done = True\n",
    "                if done:\n",
    "                    break\n",
    "            com_obs = com_obs[len(action):]\n",
    "            actions_test = actions_test[len(action):]\n",
    "    trajectories[f\"{j}\"] = traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coords = [item[0] for item in trajectories[next(iter(trajectories.keys()))]]\n",
    "y_coords = [item[1] for item in trajectories[next(iter(trajectories.keys()))]]\n",
    "# z_coords = [item[5] for item in trajectories[next(iter(trajectories.keys()))]]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot XYZ coordinates\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(len(x_coords)), x_coords, label='X', linestyle='-', linewidth=1)  # Adjust line width here\n",
    "plt.plot(range(len(y_coords)), y_coords, label='Y', linestyle='-', linewidth=1)  # Adjust line width here\n",
    "# plt.plot(range(len(z_coords)), z_coords, label='Z', linestyle='-', linewidth=1)  # Adjust line width here\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(f'Pred - XYZ Coordinates')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Coordinates')\n",
    "\n",
    "# Plot Euler angles\n",
    "# roll = [item[0] for item in trajectories[next(iter(trajectories.keys()))]]\n",
    "# pitch = [item[1] for item in trajectories[next(iter(trajectories.keys()))]]\n",
    "# yaw = [item[2] for item in trajectories[next(iter(trajectories.keys()))]]\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(range(len(roll)), roll, label='Roll', linestyle='-', linewidth=1)  # Adjust line width here\n",
    "# plt.plot(range(len(pitch)), pitch, label='Pitch', linestyle='-', linewidth=1)  # Adjust line width here\n",
    "# plt.plot(range(len(yaw)), yaw, label='Yaw', linestyle='-', linewidth=1)  # Adjust line width here\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.title(f'{next(iter(trajectories.keys()))} - Euler Angles')\n",
    "# plt.xlabel('Frame')\n",
    "# plt.ylabel('Euler Angles (Radians)')\n",
    "\n",
    "\n",
    "x_coords = [item[0] for item in splits_action[0]]\n",
    "y_coords = [item[1] for item in splits_action[0]]\n",
    "# z_coords = [item[5] for item in trajectories[next(iter(trajectories.keys()))]]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot XYZ coordinates\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(len(x_coords)), x_coords, label='X', linestyle='-', linewidth=1)  # Adjust line width here\n",
    "plt.plot(range(len(y_coords)), y_coords, label='Y', linestyle='-', linewidth=1)  # Adjust line width here\n",
    "# plt.plot(range(len(z_coords)), z_coords, label='Z', linestyle='-', linewidth=1)  # Adjust line width here\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(f'Orignal - XYZ Coordinates')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Coordinates')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV and extract each row as a list\n",
    "import csv\n",
    "\n",
    "# Initialize an empty list to store lists from CSV\n",
    "lists_from_csv = trajectories[trajectories.keys()[0]]\n",
    "\n",
    "with open('data1.csv', 'w+') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    header = ['rx', 'ry', 'rz', 'x', 'y', 'z', 'sx', 'sy', 'sz', 'x', 'y', 'z','GA']\n",
    "    writer.writerow(header)\n",
    "    for i in range(len(lists_from_csv)):\n",
    "        writer.writerow(lists_from_csv[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROBODK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robodk import robolink    # RoboDK API\n",
    "from robodk import robomath    # Robot toolbox\n",
    "RL = robolink.Robolink()\n",
    "from robodk import *      # RoboDK API\n",
    "from robolink import *    # Robot toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def XYZwxyz_2_Pose(XYZwxyz):\n",
    "    '''\n",
    "    XYZwxyz --> Pose (Homegeneous 4X4 Matrix)\n",
    "    this converts XYZ Quat to corresponding Homogeneous Matrix\n",
    "    '''\n",
    "    # print(XYZwxyz[3:])\n",
    "    _pose_matrix_without_XYZ = quaternion_2_pose(XYZwxyz[3:])\n",
    "    for i in range(3):\n",
    "        # print(XYZwxyz[i])\n",
    "        # print(XYZwxyz[i] - 1000)\n",
    "        if i == 0:\n",
    "            _pose_matrix_without_XYZ[i,3] = XYZwxyz[i] - 0\n",
    "        else:\n",
    "            _pose_matrix_without_XYZ[i,3] = XYZwxyz[i]\n",
    "    return _pose_matrix_without_XYZ\n",
    "\n",
    "def Pose_2_XYZwxyz(pose):\n",
    "    wxyz=pose_2_quaternion(pose)\n",
    "    XYZ = [pose[i,3] for i in range(3)]\n",
    "    return [*XYZ, *wxyz]\n",
    "\n",
    "\n",
    "def MuJoCo_2_RoboDK(XYZwxyz):\n",
    "    '''\n",
    "    MuJoCo(XYZwxyz) --> ROBODK(XYZwxyz)\n",
    "    this only takes XYZ and Quaternion and converts from MuJoCo(XYZwxyz) to ROBODK(XYZwxyz)\n",
    "    -----\n",
    "    converts meter -> millimeter\n",
    "    '''\n",
    "    for i in range(3):\n",
    "        # print(\"i -\",i)\n",
    "        # print(XYZwxyz[i]) \n",
    "        # XYZwxyz[1]= XYZwxyz[1] + 0.07\n",
    "        XYZwxyz[i]*=1000\n",
    "        # ccma = CCMA(w_ma=5, w_cc=3)\n",
    "        # XYZwxyz[i] = ccma.filter(XYZwxyz[i])\n",
    "    #     print(XYZwxyz[i]) \n",
    "    #     print(\"************\")\n",
    "    # print(XYZwxyz)\n",
    "    return XYZwxyz\n",
    "\n",
    "\n",
    "world_frame = RL.Item(\"dual_arm_station\")\n",
    "robot0 = RL.Item(\"robot0\")\n",
    "WORLD_T_ROBOT0 = XYZwxyz_2_Pose(MuJoCo_2_RoboDK([0, 0.880, 0, 0, 0, 0, 0]))\n",
    "# print(f\"WORLD_T_ROBOT0:\\n\\n{WORLD_T_ROBOT0}\\n\\********\\n\\n\")\n",
    "\n",
    "robot1 = RL.Item(\"robot1\")\n",
    "WORLD_T_ROBOT1 = XYZwxyz_2_Pose(MuJoCo_2_RoboDK([0, -0.470, 0.0, 0, 0, 0, 0]))\n",
    "# print(f\"WORLD_T_ROBOT1:\\n\\n{WORLD_T_ROBOT1}\\n\\********\\n\\n\")\n",
    "\n",
    "\n",
    "_TARGET0_parent = RL.Item(\"targets_robot0\"); RL.Delete(_TARGET0_parent) #Clear Worksapce\n",
    "_robot0_base = RL.Item(\"robot0_base\")\n",
    "_TARGET0_parent = RL.AddFrame(\"targets_robot0\", itemparent=_robot0_base); _TARGET0_parent.setVisible(False)\n",
    "_TARGET0_parent.setPose(eye())\n",
    "\n",
    "_TARGET1_parent = RL.Item(\"targets_robot1\"); RL.Delete(_TARGET1_parent) #Clear Worksapce\n",
    "_robot1_base = RL.Item(\"robot1_base\")\n",
    "_TARGET1_parent = RL.AddFrame(\"targets_robot1\", itemparent=_robot1_base); _TARGET1_parent.setVisible(False)\n",
    "_TARGET1_parent.setPose(eye())\n",
    "\n",
    "\n",
    "joint_robot0 = []\n",
    "joint_robot1 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORGINAL traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list = test_df\n",
    "# Base path\n",
    "base_path = \"/home/cam/Documents/test_mujoco_2/Archive/sean & Li 2 exports/\"\n",
    "collums = list.columns\n",
    "\n",
    "result_dict = {}\n",
    "count = 0\n",
    "for i in range(len(list)):\n",
    "    if list[collums[3]][i] == 'accept':\n",
    "        result_dict[count] = {\n",
    "            'Path': base_path + str(list[collums[0]][i]) + '.csv',\n",
    "            'start_frame': list[collums[1]][i],\n",
    "            'end_frame': list[collums[2]][i],\n",
    "            'Note': list[collums[4]][i]\n",
    "        }\n",
    "        count += 1\n",
    "\n",
    "# for key in result_dict:\n",
    "GXYZ, Grxyz, SXYZ, Srxyz, BXYZ, Brxyz, DXYZ, Drxyz, index , GA = extract_data(result_dict, sample_size)\n",
    "count_g = 0\n",
    "count_s = 0\n",
    "\n",
    "for index, _ in enumerate(zip(GXYZ, Grxyz, SXYZ, Srxyz)):\n",
    "\n",
    "    # if index >= 2020 and index <= 2150:\n",
    "    if index <= 127:\n",
    "\n",
    "        print(index)\n",
    "        # print(\"SCOOPER-\",[*SXYZ[index] , *Swxyz[index]])\n",
    "        _TARGET0_index_XYZrxyz = MuJoCo_2_RoboDK([*SXYZ[index] , *Srxyz[index]])\n",
    "        print(\"TARGET0 -\",_TARGET0_index_XYZrxyz)\n",
    "        _TARGET0 = RL.AddTarget(str(f'test-{index}'), itemparent=_TARGET0_parent, itemrobot=robot0)\n",
    "        _TARGET0.setPoseAbs(xyzrpw_2_pose(_TARGET0_index_XYZrxyz))\n",
    "        count_s += 1\n",
    "\n",
    "        # print(\"GRIPPER -\",[*GXYZ[index] , *Gwxyz[index]])\n",
    "        _TARGET1_index_XYZrxyz = MuJoCo_2_RoboDK([*GXYZ[index] , *Grxyz[index]])\n",
    "        print(\"TARGET1 -\",_TARGET1_index_XYZrxyz)\n",
    "        _TARGET1 = RL.AddTarget(str(f'test-{index}'), itemparent=_TARGET1_parent, itemrobot=robot1)\n",
    "        _TARGET1.setPoseAbs(xyzrpw_2_pose(_TARGET1_index_XYZrxyz))\n",
    "        count_g += 1\n",
    "    \n",
    "print(f\"Total Gripper Targets: {count_g}\")\n",
    "print(f\"Total Scooper Targets: {count_s}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(GXYZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted Traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break_point=0\n",
    "# for key in result_dict:\n",
    "for key in trajectories:\n",
    "\n",
    "    count_g = 0\n",
    "    count_s = 0\n",
    "    # break_point += 1\n",
    "    if break_point == 1:\n",
    "        break\n",
    "    print(\"Break_point -\",break_point)\n",
    "    cartesian_pose0= []\n",
    "    cartesian_pose1= []\n",
    "    for index, value in enumerate(trajectories[key]):\n",
    "        Grxyz = value[:3]\n",
    "        GXYZ = value[3:6]\n",
    "        Srxyz = value[6:9]\n",
    "        SXYZ = value[9:12]\n",
    "\n",
    "        _TARGET0_index_XYZrxyz = MuJoCo_2_RoboDK([*SXYZ , *Srxyz])\n",
    "        print(\"TARGET0 -\",_TARGET0_index_XYZrxyz)\n",
    "        _TARGET0 = RL.AddTarget(str(f'test-{index}'), itemparent=_TARGET0_parent, itemrobot=robot0)\n",
    "        _TARGET0.setPoseAbs(xyzrpw_2_pose(_TARGET0_index_XYZrxyz))\n",
    "        count_s += 1\n",
    "\n",
    "        # print(\"GRIPPER -\",[*GXYZ[index] , *Gwxyz[index]])\n",
    "        _TARGET1_index_XYZrxyz = MuJoCo_2_RoboDK([*GXYZ , *Grxyz])\n",
    "        print(\"TARGET1 -\",_TARGET1_index_XYZrxyz)\n",
    "        _TARGET1 = RL.AddTarget(str(f'test-{index}'), itemparent=_TARGET1_parent, itemrobot=robot1)\n",
    "        _TARGET1.setPoseAbs(xyzrpw_2_pose(_TARGET1_index_XYZrxyz))\n",
    "        count_g += 1\n",
    "    break_point += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_mujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
