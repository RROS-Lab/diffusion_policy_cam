{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"numpy<2.0.0\" pandas matplotlib tqdm torch diffusers scipy zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
    "from diffusers.training_utils import EMAModel\n",
    "from diffusers.optimization import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "import submodules.data_filter as _df\n",
    "import diffusion_pipline.data_processing as dproc\n",
    "import diffusion_pipline.model as md\n",
    "import submodules.cleaned_file_parser as cfp\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/home/cam/Documents/raj/diffusion_policy_cam/no-sync/checkpoints/checkpoint_3Body_9_markers_960_SSSS_epoch_119.pth'\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_trajectory(first_obs, com_obs_part, statistics, obs_horizon, obs_dim, \n",
    "                        pred_horizon, action_horizon, action_dim, \n",
    "                        noise_scheduler, num_diffusion_iters,\n",
    "                        ema_noise_pred_net, device):   \n",
    "    \n",
    "    stats = statistics\n",
    "    # keep a queue of last 2 steps of observations\n",
    "    obs_deque = collections.deque(\n",
    "        [first_obs] * obs_horizon, maxlen=obs_horizon)\n",
    "\n",
    "    # save visualization and rewards\n",
    "    traj = []\n",
    "    B = 1\n",
    "    # stack the last obs_horizon (2) number of observations\n",
    "    obs_seq = np.stack(obs_deque)\n",
    "    # normalize observation\n",
    "    nobs = dproc.normalize_data(obs_seq, stats=stats['obs'])\n",
    "    # device transfer\n",
    "    nobs = torch.from_numpy(nobs).to(device, dtype=torch.float32)\n",
    "    # infer action\n",
    "    with torch.no_grad():\n",
    "        # reshape observation to (B,obs_horizon*obs_dim)\n",
    "        obs_cond = nobs.unsqueeze(0).flatten(start_dim=1)\n",
    "        \n",
    "        # initialize action from Guassian noise\n",
    "        noisy_action = torch.randn(\n",
    "            (B, pred_horizon, action_dim), device=device)\n",
    "        naction = noisy_action\n",
    "\n",
    "        # init scheduler\n",
    "        noise_scheduler.set_timesteps(num_diffusion_iters)\n",
    "\n",
    "        for k in noise_scheduler.timesteps:\n",
    "            # predict noise\n",
    "            noise_pred = ema_noise_pred_net(\n",
    "                sample=naction,\n",
    "                timestep=k,\n",
    "                global_cond=obs_cond\n",
    "            )\n",
    "\n",
    "            # inverse diffusion step (remove noise)\n",
    "            naction = noise_scheduler.step(\n",
    "                model_output=noise_pred,\n",
    "                timestep=k,\n",
    "                sample=naction\n",
    "            ).prev_sample\n",
    "\n",
    "    # unnormalize action\n",
    "    naction = naction.detach().to('cpu').numpy()\n",
    "    naction = naction[0]\n",
    "    action_pred = dproc.unnormalize_data(naction, stats=stats['action'])\n",
    "\n",
    "    # only take action_horizon number of actions\n",
    "    start = obs_horizon - 1\n",
    "    end = start + action_horizon\n",
    "    action = action_pred[start:end,:]\n",
    "\n",
    "    for i in range(len(action)):\n",
    "        action_last = list(action[i])\n",
    "        obs_deque.append(action_last + com_obs_part)\n",
    "        traj.append(action_last + com_obs_part)\n",
    "\n",
    "\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters corrsponding to\n",
    "num_epochs =checkpoint['num_epochs']\n",
    "obs_dim = checkpoint['obs_dim']\n",
    "action_dim = checkpoint['action_dim']\n",
    "# parameters\n",
    "pred_horizon = checkpoint['pred_horizon']\n",
    "obs_horizon = checkpoint['obs_horizon']\n",
    "action_horizon = checkpoint['action_horizon']\n",
    "target_fps = checkpoint['target_fps']\n",
    "\n",
    "action_item = checkpoint['action_item']\n",
    "obs_item = checkpoint['obs_item']\n",
    "\n",
    "\n",
    "# create network object\n",
    "noise_pred_net = md.ConditionalUnet1D(\n",
    "    input_dim=action_dim,\n",
    "    global_cond_dim=obs_dim*obs_horizon\n",
    ")\n",
    "\n",
    "# example inputs\n",
    "noised_action = torch.randn((1, pred_horizon, action_dim))\n",
    "obs = torch.zeros((1, obs_horizon, obs_dim))\n",
    "diffusion_iter = torch.zeros((1,))\n",
    "\n",
    "# the noise prediction network\n",
    "# takes noisy action, diffusion iteration and observation as input\n",
    "# predicts the noise added to action\n",
    "noise = noise_pred_net(\n",
    "    sample=noised_action,\n",
    "    timestep=diffusion_iter,\n",
    "    global_cond=obs.flatten(start_dim=1))\n",
    "\n",
    "# illustration of removing noise\n",
    "# the actual noise removal is performed by NoiseScheduler\n",
    "# and is dependent on the diffusion noise schedule\n",
    "denoised_action = noised_action - noise\n",
    "\n",
    "# for this demo, we use DDPMScheduler with 100 diffusion iterations\n",
    "num_diffusion_iters = 100\n",
    "noise_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=num_diffusion_iters,\n",
    "    # the choise of beta schedule has big impact on performance\n",
    "    # we found squared cosine works the best\n",
    "    beta_schedule='squaredcos_cap_v2',\n",
    "    # clip output to [-1,1] to improve stability\n",
    "    clip_sample=True,\n",
    "    # our network predicts noise (instead of denoised action)\n",
    "    prediction_type='epsilon'\n",
    ")\n",
    "\n",
    "# device transfer\n",
    "device = torch.device('cuda')\n",
    "_ = noise_pred_net.to(device)\n",
    "\n",
    "# Exponential Moving Average\n",
    "# accelerates training and improves stability\n",
    "# holds a copy of the model weights\n",
    "ema = EMAModel(\n",
    "    parameters=noise_pred_net.parameters(),\n",
    "    power=0.75)\n",
    "\n",
    "# Standard ADAM optimizer\n",
    "# Note that EMA parametesr are not optimized\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=noise_pred_net.parameters(),\n",
    "    lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "# Cosine LR schedule with linear warmup\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='cosine',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=200,\n",
    "    num_training_steps=checkpoint['len_dataloader'] * num_epochs\n",
    ")\n",
    "\n",
    "ema_noise_pred_net = noise_pred_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_pred_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "ema.load_state_dict(checkpoint['ema_state_dict'])\n",
    "start_epoch = checkpoint['epoch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 1 gpus\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Use\", torch.cuda.device_count(), 'gpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
