{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
    "from diffusers.training_utils import EMAModel\n",
    "from diffusers.optimization import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "import submodules.data_filter as _df\n",
    "import diffusion_pipline.data_processing as dproc\n",
    "import diffusion_pipline.model as md\n",
    "import submodules.cleaned_file_parser as cfp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/home1/shuklar/diff_files/checkpoints/checkpoint__3BODY_NoNAN_12_markers__epoch_119.pth'\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'ema_state_dict', 'len_dataloader', 'dataset_stats', 'num_epochs', 'obs_dim', 'action_dim', 'pred_horizon', 'obs_horizon', 'action_horizon', 'target_fps', 'action_item', 'obs_item', 'marker_item', 'num_diffusion_iters'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 6.678683e+07\n"
     ]
    }
   ],
   "source": [
    "# observation and action dimensions corrsponding to\n",
    "num_epochs =checkpoint['num_epochs']\n",
    "obs_dim = checkpoint['obs_dim']\n",
    "action_dim = checkpoint['action_dim']\n",
    "# parameters\n",
    "pred_horizon = checkpoint['pred_horizon']\n",
    "obs_horizon = checkpoint['obs_horizon']\n",
    "action_horizon = checkpoint['action_horizon']\n",
    "target_fps = checkpoint['target_fps']\n",
    "\n",
    "type = '3BODY_NoNAN_12_markers'\n",
    "\n",
    "action_item = checkpoint['action_item']\n",
    "obs_item = checkpoint['obs_item']\n",
    "\n",
    "\n",
    "# create network object\n",
    "noise_pred_net = md.ConditionalUnet1D(\n",
    "    input_dim=action_dim,\n",
    "    global_cond_dim=obs_dim*obs_horizon\n",
    ")\n",
    "\n",
    "# example inputs\n",
    "noised_action = torch.randn((1, pred_horizon, action_dim))\n",
    "obs = torch.zeros((1, obs_horizon, obs_dim))\n",
    "diffusion_iter = torch.zeros((1,))\n",
    "\n",
    "# the noise prediction network\n",
    "# takes noisy action, diffusion iteration and observation as input\n",
    "# predicts the noise added to action\n",
    "noise = noise_pred_net(\n",
    "    sample=noised_action,\n",
    "    timestep=diffusion_iter,\n",
    "    global_cond=obs.flatten(start_dim=1))\n",
    "\n",
    "# illustration of removing noise\n",
    "# the actual noise removal is performed by NoiseScheduler\n",
    "# and is dependent on the diffusion noise schedule\n",
    "denoised_action = noised_action - noise\n",
    "\n",
    "# for this demo, we use DDPMScheduler with 100 diffusion iterations\n",
    "num_diffusion_iters = checkpoint['num_diffusion_iters']\n",
    "noise_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=num_diffusion_iters,\n",
    "    # the choise of beta schedule has big impact on performance\n",
    "    # we found squared cosine works the best\n",
    "    beta_schedule='squaredcos_cap_v2',\n",
    "    # clip output to [-1,1] to improve stability\n",
    "    clip_sample=True,\n",
    "    # our network predicts noise (instead of denoised action)\n",
    "    prediction_type='epsilon'\n",
    ")\n",
    "\n",
    "# device transfer\n",
    "device = torch.device('cuda')\n",
    "_ = noise_pred_net.to(device)\n",
    "\n",
    "# Exponential Moving Average\n",
    "# accelerates training and improves stability\n",
    "# holds a copy of the model weights\n",
    "ema = EMAModel(\n",
    "    parameters=noise_pred_net.parameters(),\n",
    "    power=0.75)\n",
    "\n",
    "# Standard ADAM optimizer\n",
    "# Note that EMA parametesr are not optimized\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=noise_pred_net.parameters(),\n",
    "    lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "# Cosine LR schedule with linear warmup\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='cosine',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=200,\n",
    "    num_training_steps=checkpoint['len_dataloader'] * num_epochs\n",
    ")\n",
    "\n",
    "\n",
    "ema_noise_pred_net = noise_pred_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_pred_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "ema.load_state_dict(checkpoint['ema_state_dict'])\n",
    "start_epoch = checkpoint['epoch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3095, 5063, 8419, 10635, 14427, 17353, 20118, 22869, 25896, 28732, 31432, 34270, 37238, 39821, 42379, 44891, 47448, 50579, 53660, 56306, 59427, 62150, 64198, 67155, 69420, 71996, 74912, 77980, 81110, 84353, 86834, 89743, 93045, 96123, 97798, 100753, 103670, 106565, 109619, 112631, 115598, 117237, 119112, 121914, 124865, 127158, 129965, 132497, 135419, 137464, 139599, 143361, 146335, 149649, 152159, 155234, 157761, 160944, 163861, 166752, 169925, 173103, 174948, 178568, 181260, 184644, 187927, 190434, 193211, 196311, 199810, 203219, 206286, 208321, 211388, 213798, 216446, 219630, 222135, 224802, 227607, 230762, 233510, 235940, 238321, 240758, 242738, 246382, 249290, 251530, 255003, 257856, 260855, 263461, 265365, 266959, 270430, 273310, 276706, 279553, 281728, 283972, 286923, 290165, 292908, 296085, 298076, 300414, 303991, 306617, 310130, 312556, 316284, 318713, 321840, 324169, 327766, 330450, 332516, 335406, 337593, 341079, 343730, 346426, 349294, 351737, 355158, 357945, 360565, 363296, 366332, 369187, 371923, 374920, 378692, 381708, 383716, 387064, 389587, 392492, 395760, 399372, 402705, 405428, 408428, 411067, 413923, 416682, 419489, 422236, 425196, 428009, 430928, 434894, 436736, 439809, 443160, 445081, 447687, 450866, 454136, 456949, 460062, 462488, 466536, 469165, 473001, 475723, 477496, 481198, 484503, 487615, 490818, 493593, 495583, 498463, 501755, 504728, 507822, 511099, 513665, 516767, 519301, 522051, 525004, 528389, 531497, 533774, 536995, 539785, 541881, 544725, 547493, 550468, 553319, 556252, 558668, 560933, 564892, 568131, 570413, 572931, 575813, 577874, 580652, 583286, 587850, 590893, 594506, 597069, 599142, 602023, 605158, 607230, 610310, 613351, 616147, 618572, 621772, 624678, 627542, 629659, 632576, 634927, 637901, 641340, 644292, 646792, 650150, 653521, 656195, 659095, 661909, 664822, 667406, 671298, 673563, 676497, 679142, 683313, 685263, 688284, 690800, 694338, 697198, 699260, 701106, 703418, 706298, 708897, 712529, 715600, 718919, 721330, 723389, 726544, 729178, 733326, 736242, 738491, 741055, 743252, 746306, 749429, 752477, 755589, 758675, 761604, 765300, 768410, 770823, 773263, 776103, 778977, 782180, 784413, 787616, 790827, 793736, 796768, 798986, 802201, 804445, 807608, 810286, 815150, 817491, 820800, 824447, 827735, 830587, 832341, 835291, 838386, 842620, 846353, 849721, 852056, 855892, 858697, 861542, 864519, 868802, 870690, 873701, 876474, 879398, 883094, 885747, 889305, 891702, 894074, 896756, 899273, 902069, 905133, 906959, 908626, 911383, 914300, 917534, 920276, 923427, 926518, 928293, 929992, 932839, 935938, 939390, 941386, 943437, 946721, 948671, 951996, 954377, 957426, 960462, 963075, 965880, 968582, 971808, 973998, 976494, 979237, 982123, 985056, 988036, 990573, 993712, 996505, 999087, 1002540, 1005699, 1008745, 1010800, 1013898, 1016902, 1021076, 1024471, 1027773, 1030735, 1033718, 1036347, 1039167, 1042435, 1045787, 1049418, 1052742, 1056187, 1058225, 1060215, 1063592, 1066327, 1068974, 1072467, 1075354, 1077560, 1080336, 1083853, 1086839, 1089116, 1090784, 1093629, 1096523, 1099705, 1102190, 1104776, 1107376, 1110249, 1113418, 1116607, 1119018, 1122267, 1126131, 1129181, 1131945, 1135047, 1137233, 1140056, 1143516, 1146645, 1149170, 1152417, 1155581, 1158456, 1161620, 1164354, 1168684, 1171838, 1175205, 1178334]\n",
      "batch['obs'].shape: torch.Size([256, 2, 54])\n",
      "batch['action'].shape torch.Size([256, 16, 18])\n"
     ]
    }
   ],
   "source": [
    "# create dataset from file\n",
    "# path_name = \"/home/cam/Downloads/Supporting Data - Sheet1.csv\"\n",
    "base_path = \"/home1/shuklar/diff_files/trun_table_task/train_traj/\"\n",
    "\n",
    "# Load data\n",
    "dict_of_df_rigid = {}\n",
    "dict_of_df_marker = {}\n",
    "\n",
    "\n",
    "for file in os.listdir(base_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        path_name = base_path + file\n",
    "        data = cfp.DataParser.from_quat_file(file_path = path_name, target_fps=target_fps, filter=False, window_size=15, polyorder=3)\n",
    "        marker_data = data.get_marker_Txyz()\n",
    "        data_state_dict = data.get_rigid_TxyzRxyz()\n",
    "\n",
    "        dicts = [data_state_dict, marker_data]\n",
    "        trimmed_dicts = _df.trim_lists_in_dicts(dicts)\n",
    "\n",
    "        dict_of_df_rigid[file] = trimmed_dicts[0]\n",
    "        dict_of_df_marker[file] = trimmed_dicts[1]\n",
    "\n",
    "item_name = data.rigid_bodies\n",
    "marker_name = data.markers\n",
    "\n",
    "if len(dict_of_df_rigid) == len(dict_of_df_marker):\n",
    "\n",
    "    rigiddataset, index = _df.episode_combiner(dict_of_df_rigid, item_name)\n",
    "    markerdataset, _ = _df.episode_combiner(dict_of_df_marker, marker_name)\n",
    "    print(index[action_item[0]])\n",
    "\n",
    "\n",
    "#### if you don't want battery info then just do obs_item = None abd also do clear all outputs and restart the kernal before that and satrt from the top \n",
    "\n",
    "\n",
    "dataset = dproc.TaskStateDataset(Rigiddataset=rigiddataset, Velocitydataset = None, Markerdataset= markerdataset, index= index[action_item[0]], \n",
    "                                 action_item = action_item, obs_item = obs_item,\n",
    "                                 marker_item= marker_name,\n",
    "                                 pred_horizon=pred_horizon,\n",
    "                                 obs_horizon=obs_horizon,\n",
    "                                 action_horizon=action_horizon)\n",
    "\n",
    "# create dataloader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    num_workers=1,\n",
    "    shuffle=True,\n",
    "    # accelerate cpu-gpu transfer\n",
    "    pin_memory=True,\n",
    "    # don't kill worker process afte each epoch\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "print(\"batch['obs'].shape:\", batch['obs'].shape)\n",
    "print(\"batch['action'].shape\", batch['action'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24.576021  ,  72.273773  , 362.534119  ,  -1.58459063,\n",
       "         0.43490431,  -1.52324078])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_state_dict['chisel'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-194.145798  ,  259.163086  ,  402.422455  ,   -1.75266852,\n",
       "          1.23180474,    1.77237689])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_state_dict['gripper'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.11871452e+02,  3.45810364e+02,  1.74228607e+02, -3.31561306e-03,\n",
       "       -2.91190058e-03, -2.47683353e-03])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_state_dict['battery'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 64.510429, 476.06546 , 179.830948])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marker_data['B1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/280 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#@markdown ### **Training**\n",
    "#@markdown\n",
    "\n",
    "checkpoint_dir = 'checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_interval = 3600\n",
    "last_checkpoint_time = time.time()\n",
    "\n",
    "\n",
    "with tqdm(range(num_epochs -  start_epoch), desc='Epoch') as tglobal:\n",
    "    # epoch loop\n",
    "    epoch_loss = []\n",
    "    batch_loss_per_epoch = []\n",
    "\n",
    "    for epoch_idx in tglobal:\n",
    "        batch_loss = []\n",
    "        batch_noise = []\n",
    "        # batch loop\n",
    "        for nbatch in dataloader:\n",
    "            # data normalized in dataset\n",
    "            # device transfer\n",
    "            nobs = nbatch['obs']\n",
    "            naction = nbatch['action']\n",
    "            B = nobs.shape[0]\n",
    "\n",
    "            # observation as FiLM conditioning\n",
    "            # (B, obs_horizon, obs_dim)\n",
    "            obs_cond = nobs[:,:obs_horizon,:]\n",
    "            # (B, obs_horizon * obs_dim)\n",
    "            obs_cond = obs_cond.flatten(start_dim=1).float().to(device)\n",
    "            # print(obs_cond.type())\n",
    "\n",
    "            # sample noise to add to actions\n",
    "            # noise = torch.randn(naction.shape, device=device)\n",
    "            noise = torch.randn(naction.shape)\n",
    "\n",
    "            # sample a diffusion iteration for each data point\n",
    "            timesteps = torch.randint(\n",
    "                0, noise_scheduler.config.num_train_timesteps,\n",
    "                (B,)\n",
    "            ).long()\n",
    "\n",
    "            # add noise to the clean images according to the noise magnitude at each diffusion iteration\n",
    "            # (this is the forward diffusion process)\n",
    "            noisy_actions = noise_scheduler.add_noise(\n",
    "                naction, noise, timesteps)\n",
    "            \n",
    "            noise = noise.to(device)\n",
    "            \n",
    "            timesteps = timesteps.to(device)\n",
    "\n",
    "            # print(noisy_actions.type())\n",
    "            noisy_actions = noisy_actions.type(torch.FloatTensor).to(device)\n",
    "            # print(noisy_actions.type())\n",
    "\n",
    "            # predict the noise residual\n",
    "            noise_pred = noise_pred_net(\n",
    "                noisy_actions, timesteps, global_cond=obs_cond)\n",
    "            \n",
    "            batch_noise.append(noise_pred)\n",
    "\n",
    "            # L2 loss\n",
    "            loss = nn.functional.mse_loss(noise_pred, noise)\n",
    "\n",
    "            # optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # step lr scheduler every batch\n",
    "            # this is different from standard pytorch behavior\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            # update Exponential Moving Average of the model weights\n",
    "            ema.step(noise_pred_net)\n",
    "            # print(ema.state_dict)\n",
    "\n",
    "            # logging\n",
    "            loss_cpu = loss.item()\n",
    "            batch_loss.append(loss_cpu)\n",
    "            # tglobal.set_postfix(loss=loss_cpu)\n",
    "\n",
    "        # save checkpoint\n",
    "        # went to the emma model library and added state_dict to the model\n",
    "        current_time = time.time()\n",
    "        if current_time - last_checkpoint_time > checkpoint_interval:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_{type}_epoch_{epoch_idx}.pth')\n",
    "            torch.save({\n",
    "                        'epoch': epoch_idx + start_epoch,\n",
    "                        'model_state_dict': noise_pred_net.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "                        'ema_state_dict': ema.state_dict(),\n",
    "                        'len_dataloader': len(dataloader),\n",
    "                        'dataset_stats': dataset.stats,\n",
    "                        'num_epochs': num_epochs,\n",
    "                        'obs_dim': obs_dim,\n",
    "                        'action_dim': action_dim,\n",
    "                        'pred_horizon': pred_horizon,\n",
    "                        'obs_horizon': obs_horizon,\n",
    "                        'action_horizon': action_horizon,\n",
    "                        'target_fps': target_fps,\n",
    "                        'action_item': action_item,\n",
    "                        'obs_item': obs_item,\n",
    "                        'marker_item': marker_name,\n",
    "                        'num_diffusion_iters': num_diffusion_iters,\n",
    "                    }, checkpoint_path)\n",
    "            last_checkpoint_time = current_time\n",
    "            \n",
    "        tglobal.set_postfix(loss=np.mean(batch_loss))\n",
    "        epoch_loss.append(np.mean(batch_loss))\n",
    "        batch_loss_per_epoch.append(batch_loss)\n",
    "\n",
    "# Weights of the EMA model\n",
    "# is used for inference\n",
    "ema_noise_pred_net = noise_pred_net\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_{type}_epoch_{epoch_idx}.pth')\n",
    "torch.save({\n",
    "    'epoch': epoch_idx + start_epoch,\n",
    "    'model_state_dict': noise_pred_net.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "    'ema_state_dict': ema.state_dict(),\n",
    "    'len_dataloader': len(dataloader),\n",
    "    'dataset_stats': dataset.stats,\n",
    "    'num_epochs': num_epochs,\n",
    "    'obs_dim': obs_dim,\n",
    "    'action_dim': action_dim,\n",
    "    'pred_horizon': pred_horizon,\n",
    "    'obs_horizon': obs_horizon,\n",
    "    'action_horizon': action_horizon,\n",
    "    'target_fps': target_fps,\n",
    "    'action_item': action_item,\n",
    "    'obs_item': obs_item,\n",
    "    'marker_item': marker_name,\n",
    "    'num_diffusion_iters': num_diffusion_iters,\n",
    "}, checkpoint_path)\n",
    "print(f'Checkpoint saved at epoch {epoch_idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
