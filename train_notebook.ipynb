{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Sequence, Dict, Union, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import collections\n",
    "import zarr\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
    "from diffusers.training_utils import EMAModel\n",
    "from diffusers.optimization import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "import submodules.data_filter as _df\n",
    "import diffusion_pipline.data_processing as dproc\n",
    "import diffusion_pipline.model as md\n",
    "import submodules.cleaned_file_parser as cfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation and action dimensions corrsponding to\n",
    "# the output of PushTEnv\n",
    "# obs_dim = 25\n",
    "# action_dim = 13\n",
    "\n",
    "obs_dim = 25\n",
    "action_dim = 13\n",
    "# parameters\n",
    "pred_horizon = 16\n",
    "obs_horizon = 2\n",
    "action_horizon = 8\n",
    "sample_size = 8\n",
    "\n",
    "action_item = ['chisel', 'gripper']\n",
    "obs_item = ['battery']\n",
    "\n",
    "# create network object\n",
    "noise_pred_net = md.ConditionalUnet1D(\n",
    "    input_dim=action_dim,\n",
    "    global_cond_dim=obs_dim*obs_horizon\n",
    ")\n",
    "\n",
    "# example inputs\n",
    "noised_action = torch.randn((1, pred_horizon, action_dim))\n",
    "obs = torch.zeros((1, obs_horizon, obs_dim))\n",
    "diffusion_iter = torch.zeros((1,))\n",
    "\n",
    "# the noise prediction network\n",
    "# takes noisy action, diffusion iteration and observation as input\n",
    "# predicts the noise added to action\n",
    "noise = noise_pred_net(\n",
    "    sample=noised_action,\n",
    "    timestep=diffusion_iter,\n",
    "    global_cond=obs.flatten(start_dim=1))\n",
    "\n",
    "# illustration of removing noise\n",
    "# the actual noise removal is performed by NoiseScheduler\n",
    "# and is dependent on the diffusion noise schedule\n",
    "denoised_action = noised_action - noise\n",
    "\n",
    "# for this demo, we use DDPMScheduler with 100 diffusion iterations\n",
    "num_diffusion_iters = 100\n",
    "noise_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=num_diffusion_iters,\n",
    "    # the choise of beta schedule has big impact on performance\n",
    "    # we found squared cosine works the best\n",
    "    beta_schedule='squaredcos_cap_v2',\n",
    "    # clip output to [-1,1] to improve stability\n",
    "    clip_sample=True,\n",
    "    # our network predicts noise (instead of denoised action)\n",
    "    prediction_type='epsilon'\n",
    ")\n",
    "\n",
    "# device transfer\n",
    "device = torch.device('cuda')\n",
    "_ = noise_pred_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset from file\n",
    "# path_name = \"/home/cam/Downloads/Supporting Data - Sheet1.csv\"\n",
    "base_path = \"/home/cam/Documents/diffusion_policy_cam/diffusion_pipline/data_chisel_task/cleaned_traj/\"\n",
    "\n",
    "# Load data\n",
    "dict_of_df_rigid = {}\n",
    "dict_of_df_marker = {}\n",
    "\n",
    "\n",
    "for file in os.listdir(base_path):\n",
    "    if file.endswith(\".csv\") and file.startswith(\"cap\"):\n",
    "        path_name = base_path + file\n",
    "        data = cfp.DataParser.from_quat_file(file_path = path_name, target_fps=120.0, filter=False, window_size=15, polyorder=3)\n",
    "        dict_of_df_rigid[file] = data.get_rigid_TxyzRxyz()\n",
    "        dict_of_df_marker[file] = data.get_marker_Txyz()\n",
    "        \n",
    "item_name = data.rigid_bodies\n",
    "marker_name = data.markers\n",
    "\n",
    "if len(dict_of_df_rigid) == len(dict_of_df_marker):\n",
    "\n",
    "    rigiddataset, index = _df.episode_combiner(dict_of_df_rigid, item_name)\n",
    "    markerdataset, _ = _df.episode_combiner(dict_of_df_marker, marker_name)\n",
    "    print(index[action_item[0]])\n",
    "\n",
    "dataset = dproc.TaskStateDataset(rigiddataset, markerdataset, index[action_item[0]], \n",
    "                                 action_item = action_item, obs_item = obs_item,\n",
    "                                 marker_item= marker_name,\n",
    "                                 pred_horizon=pred_horizon,\n",
    "                                 obs_horizon=obs_horizon,\n",
    "                                 action_horizon=action_horizon)\n",
    "\n",
    "# create dataloader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    num_workers=1,\n",
    "    shuffle=True,\n",
    "    # accelerate cpu-gpu transfer\n",
    "    pin_memory=True,\n",
    "    # don't kill worker process afte each epoch\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "print(\"batch['obs'].shape:\", batch['obs'].shape)\n",
    "print(\"batch['action'].shape\", batch['action'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown ### **Training**\n",
    "#@markdown\n",
    "#@markdown Takes about an hour. If you don't want to wait, skip to the next cell\n",
    "#@markdown to load pre-trained weights\n",
    "\n",
    "num_epochs =400\n",
    "checkpoint_dir = 'checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_interval = 3600\n",
    "last_checkpoint_time = time.time()\n",
    "# Exponential Moving Average\n",
    "# accelerates training and improves stability\n",
    "# holds a copy of the model weights\n",
    "ema = EMAModel(\n",
    "    parameters=noise_pred_net.parameters(),\n",
    "    power=0.75)\n",
    "\n",
    "# Standard ADAM optimizer\n",
    "# Note that EMA parametesr are not optimized\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=noise_pred_net.parameters(),\n",
    "    lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "# Cosine LR schedule with linear warmup\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='cosine',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=200,\n",
    "    num_training_steps=len(dataloader) * num_epochs\n",
    ")\n",
    "\n",
    "with tqdm(range(num_epochs), desc='Epoch') as tglobal:\n",
    "    # epoch loop\n",
    "    epoch_loss = []\n",
    "    batch_loss_per_epoch = []\n",
    "\n",
    "    for epoch_idx in tglobal:\n",
    "        batch_loss = []\n",
    "        batch_noise = []\n",
    "        # batch loop\n",
    "        with tqdm(dataloader, desc='Batch', leave=False) as tepoch:\n",
    "\n",
    "            for nbatch in tepoch:\n",
    "                # data normalized in dataset\n",
    "                # device transfer\n",
    "                nobs = nbatch['obs']\n",
    "                naction = nbatch['action']\n",
    "                B = nobs.shape[0]\n",
    "\n",
    "                # observation as FiLM conditioning\n",
    "                # (B, obs_horizon, obs_dim)\n",
    "                obs_cond = nobs[:,:obs_horizon,:]\n",
    "                # (B, obs_horizon * obs_dim)\n",
    "                obs_cond = obs_cond.flatten(start_dim=1).float().to(device)\n",
    "                # print(obs_cond.type())\n",
    "\n",
    "                # sample noise to add to actions\n",
    "                # noise = torch.randn(naction.shape, device=device)\n",
    "                noise = torch.randn(naction.shape)\n",
    "\n",
    "                # sample a diffusion iteration for each data point\n",
    "                timesteps = torch.randint(\n",
    "                    0, noise_scheduler.config.num_train_timesteps,\n",
    "                    (B,)\n",
    "                ).long()\n",
    "\n",
    "                # add noise to the clean images according to the noise magnitude at each diffusion iteration\n",
    "                # (this is the forward diffusion process)\n",
    "                noisy_actions = noise_scheduler.add_noise(\n",
    "                    naction, noise, timesteps)\n",
    "                \n",
    "                noise = noise.to(device)\n",
    "                \n",
    "                timesteps = timesteps.to(device)\n",
    "\n",
    "                # print(noisy_actions.type())\n",
    "                noisy_actions = noisy_actions.type(torch.FloatTensor).to(device)\n",
    "                # print(noisy_actions.type())\n",
    "\n",
    "                # predict the noise residual\n",
    "                noise_pred = noise_pred_net(\n",
    "                    noisy_actions, timesteps, global_cond=obs_cond)\n",
    "                \n",
    "                batch_noise.append(noise_pred)\n",
    "\n",
    "                # L2 loss\n",
    "                loss = nn.functional.mse_loss(noise_pred, noise)\n",
    "\n",
    "                # optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                # step lr scheduler every batch\n",
    "                # this is different from standard pytorch behavior\n",
    "                lr_scheduler.step()\n",
    "\n",
    "                # update Exponential Moving Average of the model weights\n",
    "                ema.step(noise_pred_net)\n",
    "                # print(ema.state_dict)\n",
    "\n",
    "                # logging\n",
    "                loss_cpu = loss.item()\n",
    "                batch_loss.append(loss_cpu)\n",
    "                tepoch.set_postfix(loss=loss_cpu)\n",
    "\n",
    "        # save checkpoint\n",
    "        # went to the emma model library and added state_dict to the model\n",
    "        current_time = time.time()\n",
    "        if current_time - last_checkpoint_time > checkpoint_interval:\n",
    "        # if epoch_idx == 2:\n",
    "            # Save model checkpoint\n",
    "            # checkpoint_path = os.path.join(checkpoint_dir, f'BOX_GRIP_checkpoint_epoch_{epoch_idx}.pth')\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'T_checkpoint_epoch_{epoch_idx}.pth')\n",
    "\n",
    "            torch.save({\n",
    "                'epoch': epoch_idx,\n",
    "                'model_state_dict': noise_pred_net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "                'ema_state_dict': ema.state_dict,\n",
    "                'loss': loss.cpu().detach().numpy(),\n",
    "            }, checkpoint_path)\n",
    "            print(f'Checkpoint saved at epoch {epoch_idx}')\n",
    "            last_checkpoint_time = current_time\n",
    "        elif epoch_idx == num_epochs:\n",
    "            # Save model checkpoint\n",
    "            # checkpoint_path = os.path.join(checkpoint_dir, f'BOX_GRIP_checkpoint_epoch_{epoch_idx}.pth')\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'T_checkpoint_epoch_{epoch_idx}.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch_idx,\n",
    "                'model_state_dict': noise_pred_net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "                'ema_state_dict': ema.state_dict,\n",
    "                'loss': loss.cpu().detach().numpy(),\n",
    "            }, checkpoint_path)\n",
    "            print(f'Checkpoint saved at epoch {epoch_idx}')\n",
    "            last_checkpoint_time = current_time\n",
    "            \n",
    "        tglobal.set_postfix(loss=np.mean(batch_loss))\n",
    "        epoch_loss.append(np.mean(batch_loss))\n",
    "        batch_loss_per_epoch.append(batch_loss)\n",
    "\n",
    "# Weights of the EMA model\n",
    "# is used for inference\n",
    "ema_noise_pred_net = noise_pred_net"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_mujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
